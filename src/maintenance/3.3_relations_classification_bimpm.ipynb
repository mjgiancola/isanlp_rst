{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Rhetorical relations classification used in tree building: Step 3. BiMPM\n",
    "\n",
    "1. Prepare data and model-related scripts.\n",
    "2. Evaluate models.\n",
    "3. Adjust and evaluate an ansemble for BiMPM and feature rich model.\n",
    "\n",
    "Output:\n",
    " - ``models/relation_predictor_bimpm/*``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Make a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models/label_predictor_bimpm'\n",
    "! mkdir $MODEL_PATH\n",
    "\n",
    "TRAIN_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_train.tsv')\n",
    "DEV_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_dev.tsv')\n",
    "TEST_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_test.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prepare train/test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IN_PATH = 'data_labeling'\n",
    "\n",
    "train_samples = pd.read_pickle(os.path.join(IN_PATH, 'train_samples.pkl'))\n",
    "dev_samples = pd.read_pickle(os.path.join(IN_PATH, 'dev_samples.pkl'))\n",
    "test_samples = pd.read_pickle(os.path.join(IN_PATH, 'test_samples.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "counts = train_samples['relation'].value_counts(normalize=False).values\n",
    "NUMBER_CLASSES = len(counts)\n",
    "print(\"number of classes:\", NUMBER_CLASSES)\n",
    "print(\"class weights:\")\n",
    "np.round(counts.min() / counts, decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_samples.relation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_samples = train_samples.reset_index()\n",
    "train_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(TRAIN_FILE_PATH, sep='\\t', header=False, index=False)\n",
    "\n",
    "dev_samples = dev_samples.reset_index()\n",
    "dev_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(DEV_FILE_PATH, sep='\\t', header=False, index=False)\n",
    "\n",
    "test_samples = test_samples.reset_index()\n",
    "test_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(TEST_FILE_PATH, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Generate config files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ELMo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile $MODEL_PATH/config_elmo.jsonnet\n",
    "\n",
    "// Configuration for a sentence matching model based on:\n",
    "//   Wang, Zhiguo, Wael Hamza, and Radu Florian. \"Bilateral multi-perspective matching for natural language sentences.\"\n",
    "//   Proceedings of the 26th International Joint Conference on Artificial Intelligence. 2017.\n",
    "\n",
    "\n",
    "local NUM_EPOCHS = 100;\n",
    "local LR = std.parseJson(std.extVar('LR'));\n",
    "local LSTM_ENCODER_HIDDEN = 50;\n",
    "local LSTM_AGG_HIDDEN = std.parseJson(std.extVar('LSTM_AGG_HIDDEN'));\n",
    "\n",
    "local dataset_reader_type = \"quora_paraphrase\";\n",
    "local model_type = \"bimpm_custom_package.model.multiclass_bimpm.BiMpm\";\n",
    "\n",
    "\n",
    "// best: LR=0.0005794893218638051\n",
    "//       LSTM_AGG_HIDDEN=73\n",
    "\n",
    "{\n",
    "  \"dataset_reader\": {\n",
    "    \"type\": dataset_reader_type,\n",
    "    \"tokenizer\": {\n",
    "      \"type\": \"just_spaces\"\n",
    "    },\n",
    "    \"token_indexers\": {\n",
    "      \"token_characters\": {\n",
    "        \"type\": \"characters\",\n",
    "        \"min_padding_length\": 30,\n",
    "      },\n",
    "      \"elmo\": {\n",
    "        \"type\": \"elmo_characters\"\n",
    "     }\n",
    "    }\n",
    "  },\n",
    "  \"train_data_path\": \"label_predictor_bimpm/nlabel_cf_train.tsv\",\n",
    "  \"validation_data_path\": \"label_predictor_bimpm/nlabel_cf_dev.tsv\",\n",
    "  \"test_data_path\": \"label_predictor_bimpm/nlabel_cf_test.tsv\",\n",
    "  \"model\": {\n",
    "    \"type\": model_type,\n",
    "    \"dropout\": 0.5,\n",
    "    \"class_weights\": [\n",
    "        0.02518 , 0.029339, 0.073593, 0.100253, 0.107207, 0.114203,\n",
    "        0.133858, 0.159732, 0.161028, 0.179758, 0.195724, 0.221601,\n",
    "        0.247917, 0.274194, 0.30829 , 0.34593 , 0.363914, 0.420495,\n",
    "        0.777778, 0.788079, 0.991667, 1.      ],\n",
    "    \"text_field_embedder\": {\n",
    "        \"token_embedders\": {\n",
    "            \"elmo\": {\n",
    "                    \"type\": \"elmo_token_embedder\",\n",
    "                    \"options_file\": \"rsv_elmo/options.json\",\n",
    "                    \"weight_file\": \"rsv_elmo/model.hdf5\",\n",
    "                    \"do_layer_norm\": false,\n",
    "                    \"projection_dim\": 100,\n",
    "                    \"dropout\": 0.0\n",
    "            },\n",
    "            \"token_characters\": {\n",
    "                \"type\": \"character_encoding\",\n",
    "                \"dropout\": 0.1,\n",
    "                \"embedding\": {\n",
    "                    \"embedding_dim\": 20,\n",
    "                    \"sparse\": false,\n",
    "                    \"vocab_namespace\": \"token_characters\"\n",
    "                },\n",
    "                \"encoder\": {\n",
    "                    \"type\": \"gru\",\n",
    "                    \"input_size\": $.model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim,\n",
    "                    \"hidden_size\": LSTM_ENCODER_HIDDEN,\n",
    "                    \"num_layers\": 1,\n",
    "                    \"bidirectional\": true,\n",
    "                    \"dropout\": 0.4\n",
    "                },\n",
    "            },\n",
    "      }\n",
    "    },\n",
    "    \"matcher_word\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": $.model.text_field_embedder.token_embedders.elmo.projection_dim+LSTM_ENCODER_HIDDEN+LSTM_ENCODER_HIDDEN,\n",
    "      \"num_perspectives\": 10,\n",
    "      \"with_full_match\": false\n",
    "    },\n",
    "    \"encoder1\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": $.model.text_field_embedder.token_embedders.elmo.projection_dim+LSTM_ENCODER_HIDDEN+LSTM_ENCODER_HIDDEN,\n",
    "      \"hidden_size\": 200,\n",
    "      \"num_layers\": 1\n",
    "    },\n",
    "    \"matcher_forward1\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"matcher_backward1\": {\n",
    "      \"is_forward\": false,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"encoder2\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": $.model.matcher_forward1.hidden_dim+$.model.matcher_backward1.hidden_dim,\n",
    "      \"hidden_size\": 200,\n",
    "      \"num_layers\": 1\n",
    "    },\n",
    "    \"matcher_forward2\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"matcher_backward2\": {\n",
    "      \"is_forward\": false,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"aggregator\":{\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 264,\n",
    "      \"hidden_size\": LSTM_AGG_HIDDEN,\n",
    "      \"num_layers\": 1,\n",
    "    },\n",
    "    \"classifier_feedforward\": {\n",
    "      \"input_dim\": LSTM_AGG_HIDDEN*4,\n",
    "      \"num_layers\": 1,\n",
    "      \"hidden_dims\": [22],\n",
    "      \"activations\": [\"mish\"],\n",
    "      \"dropout\": [0.0]\n",
    "    },\n",
    "    \"initializer\": {\n",
    "      \"regexes\": [\n",
    "        [\".*linear_layers.*weight\", {\"type\": \"xavier_normal\"}],\n",
    "        [\".*linear_layers.*bias\", {\"type\": \"constant\", \"val\": 0}],\n",
    "        [\".*weight_ih.*\", {\"type\": \"xavier_normal\"}],\n",
    "        [\".*weight_hh.*\", {\"type\": \"orthogonal\"}],\n",
    "        [\".*bias.*\", {\"type\": \"constant\", \"val\": 0}],\n",
    "        [\".*matcher.*match_weights.*\", {\"type\": \"kaiming_normal\"}]\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"data_loader\": {\n",
    "#     \"type\": 'multiprocess',\n",
    "#     \"max_instances_in_memory\": $.data_loader.batch_sampler.batch_size * 10,\n",
    "    \"batch_sampler\": {\n",
    "        \"type\": \"bucket\",\n",
    "        \"batch_size\": 8,\n",
    "        \"padding_noise\": 0.0,\n",
    "        \"sorting_keys\": [\"premise\"],\n",
    "    },\n",
    "  },\n",
    "  \"trainer\": {\n",
    "    \"num_epochs\": NUM_EPOCHS,\n",
    "    \"patience\": 5,\n",
    "    \"grad_clipping\": 5.0,\n",
    "    \"validation_metric\": \"+f1_macro\",\n",
    "    \"cuda_device\": 1,\n",
    "    \"optimizer\": {\n",
    "      \"type\": \"huggingface_adamw\",\n",
    "      \"lr\": LR\n",
    "    },\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile models/label_bimpm_params.json\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"type\": \"int\",\n",
    "    \"attributes\": {\n",
    "      \"name\": \"LSTM_AGG_HIDDEN\",\n",
    "      \"low\": 50,\n",
    "      \"high\": 100\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"float\",\n",
    "    \"attributes\": {\n",
    "      \"name\": \"LR\",\n",
    "      \"low\": 1e-4,\n",
    "      \"high\": 1e-3,\n",
    "      \"log\": true\n",
    "    }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile models/tune_label_predictor.sh\n",
    "\n",
    "export METHOD=label_predictor_bimpm\n",
    "export STUDY_NAME=label_tuning_0\n",
    "mkdir optuna\n",
    "rm -r optuna/$METHOD\n",
    "mkdir optuna/$METHOD\n",
    "\n",
    "# optuna delete-study --study-name $STUDY_NAME\n",
    "allennlp tune ${METHOD}/config_elmo.jsonnet label_bimpm_params.json --serialization-dir optuna/$METHOD \\\n",
    "    --study-name $STUDY_NAME \\\n",
    "    --skip-if-exists \\\n",
    "    --metrics best_validation_f1_macro \\\n",
    "    --direction maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def collect_optuna_results(path):\n",
    "    for trial in glob.glob(os.path.join(path, 'trial_*/')):\n",
    "        try:\n",
    "            metrics = json.load(open(os.path.join(trial, 'metrics.json')))\n",
    "            print(trial, metrics['best_validation_f1_macro'])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "collect_optuna_results('models/optuna/label_predictor_bimpm/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ELMo + fasttext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile $MODEL_PATH/config_elmo_fasttext.jsonnet\n",
    "\n",
    "// Configuration for a sentence matching model based on:\n",
    "//   Wang, Zhiguo, Wael Hamza, and Radu Florian. \"Bilateral multi-perspective matching for natural language sentences.\"\n",
    "//   Proceedings of the 26th International Joint Conference on Artificial Intelligence. 2017.\n",
    "\n",
    "\n",
    "local NUM_EPOCHS = 100;\n",
    "local LR = std.parseJson(std.extVar('LR'));\n",
    "local LSTM_ENCODER_HIDDEN = 50;\n",
    "local ELMO_DIM = 1024;\n",
    "local LSTM_AGG_HIDDEN = std.parseJson(std.extVar('LSTM_AGG_HIDDEN'));\n",
    "\n",
    "local dataset_reader_type = \"quora_paraphrase\";\n",
    "local model_type = \"bimpm_custom_package.model.multiclass_bimpm.BiMpm\";\n",
    "\n",
    "// best: LR=0.0005303721829092237\n",
    "//       LSTM_AGG_HIDDEN=83\n",
    "\n",
    "{\n",
    "  \"dataset_reader\": {\n",
    "    \"type\": dataset_reader_type,\n",
    "    \"tokenizer\": {\n",
    "      \"type\": \"just_spaces\"\n",
    "    },\n",
    "    \"token_indexers\": {\n",
    "      \"token_characters\": {\n",
    "        \"type\": \"characters\",\n",
    "        \"min_padding_length\": 30,\n",
    "      },\n",
    "      \"elmo\": {\n",
    "        \"type\": \"elmo_characters\"\n",
    "      },\n",
    "      \"tokens\": {\n",
    "        \"type\": \"single_id\",\n",
    "        \"lowercase_tokens\": true\n",
    "      },\n",
    "    }\n",
    "  },\n",
    "  \"train_data_path\": \"label_predictor_bimpm/nlabel_cf_train.tsv\",\n",
    "  \"validation_data_path\": \"label_predictor_bimpm/nlabel_cf_dev.tsv\",\n",
    "  \"test_data_path\": \"label_predictor_bimpm/nlabel_cf_test.tsv\",\n",
    "  \"model\": {\n",
    "    \"type\": model_type,\n",
    "    \"dropout\": 0.5,\n",
    "    \"class_weights\": [\n",
    "        0.02518 , 0.029339, 0.073593, 0.100253, 0.107207, 0.114203,\n",
    "        0.133858, 0.159732, 0.161028, 0.179758, 0.195724, 0.221601,\n",
    "        0.247917, 0.274194, 0.30829 , 0.34593 , 0.363914, 0.420495,\n",
    "        0.777778, 0.788079, 0.991667, 1.      ],\n",
    "    \"encode_together\": false,\n",
    "    \"text_field_embedder\": {\n",
    "        \"token_embedders\": {\n",
    "            \"tokens\": {\n",
    "                \"type\": \"embedding\",\n",
    "                \"embedding_dim\": 300,\n",
    "                \"pretrained_file\": \"ft_native_300_ru_wiki_lenta_nltk_wordpunct_tokenize.vec\",\n",
    "                \"trainable\": false\n",
    "            },\n",
    "            \"elmo\": {\n",
    "                    \"type\": \"elmo_token_embedder\",\n",
    "                    \"options_file\": \"rsv_elmo/options.json\",\n",
    "                    \"weight_file\": \"rsv_elmo/model.hdf5\",\n",
    "                    \"do_layer_norm\": false,\n",
    "                    \"projection_dim\": 100,\n",
    "                    \"dropout\": 0.0\n",
    "            },\n",
    "            \"token_characters\": {\n",
    "                \"type\": \"character_encoding\",\n",
    "                \"dropout\": 0.1,\n",
    "                \"embedding\": {\n",
    "                    \"embedding_dim\": 20,\n",
    "                    \"padding_index\": 0,\n",
    "                },\n",
    "                \"encoder\": {\n",
    "                    \"type\": \"gru\",\n",
    "                    \"input_size\": 20,\n",
    "                    \"hidden_size\": LSTM_ENCODER_HIDDEN,\n",
    "                    \"num_layers\": 1,\n",
    "                    \"bidirectional\": true,\n",
    "                },\n",
    "            },\n",
    "      }\n",
    "    },\n",
    "    \"matcher_word\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": $.model.text_field_embedder.token_embedders.elmo.projection_dim+LSTM_ENCODER_HIDDEN*2+$.model.text_field_embedder.token_embedders.tokens.embedding_dim,\n",
    "      \"num_perspectives\": 10,\n",
    "      \"with_full_match\": false\n",
    "    },\n",
    "    \"encoder1\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": $.model.text_field_embedder.token_embedders.elmo.projection_dim+LSTM_ENCODER_HIDDEN*2+$.model.text_field_embedder.token_embedders.tokens.embedding_dim,\n",
    "      \"hidden_size\": 200,\n",
    "      \"num_layers\": 1\n",
    "    },\n",
    "    \"matcher_forward1\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"matcher_backward1\": {\n",
    "      \"is_forward\": false,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"encoder2\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": $.model.matcher_forward1.hidden_dim+$.model.matcher_backward1.hidden_dim,\n",
    "      \"hidden_size\": 200,\n",
    "      \"num_layers\": 1\n",
    "    },\n",
    "    \"matcher_forward2\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"matcher_backward2\": {\n",
    "      \"is_forward\": false,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"aggregator\":{\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 264,\n",
    "      \"hidden_size\": LSTM_AGG_HIDDEN,\n",
    "      \"num_layers\": 1,\n",
    "    },\n",
    "    \"classifier_feedforward\": {\n",
    "      \"input_dim\": LSTM_AGG_HIDDEN*4,\n",
    "      \"num_layers\": 1,\n",
    "      \"hidden_dims\": [22],\n",
    "      \"activations\": [\"mish\"],\n",
    "      \"dropout\": [0.0]\n",
    "    },\n",
    "    \"initializer\": {\n",
    "      \"regexes\": [\n",
    "        [\".*linear_layers.*weight\", {\"type\": \"xavier_normal\"}],\n",
    "        [\".*linear_layers.*bias\", {\"type\": \"constant\", \"val\": 0}],\n",
    "        [\".*weight_ih.*\", {\"type\": \"xavier_normal\"}],\n",
    "        [\".*weight_hh.*\", {\"type\": \"orthogonal\"}],\n",
    "        [\".*bias.*\", {\"type\": \"constant\", \"val\": 0}],\n",
    "        [\".*matcher.*match_weights.*\", {\"type\": \"kaiming_normal\"}]\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"data_loader\": {\n",
    "    \"type\": 'multiprocess',\n",
    "    \"max_instances_in_memory\": $.data_loader.batch_sampler.batch_size * 20,\n",
    "    \"batch_sampler\": {\n",
    "        \"type\": \"bucket\",\n",
    "        \"batch_size\": 4,\n",
    "        \"padding_noise\": 0.0,\n",
    "        \"sorting_keys\": [\"premise\"],\n",
    "    },\n",
    "  },\n",
    "  \"trainer\": {\n",
    "    \"num_epochs\": NUM_EPOCHS,\n",
    "    \"patience\": 5,\n",
    "    \"grad_clipping\": 5.0,\n",
    "    \"validation_metric\": \"+f1_macro\",\n",
    "    \"cuda_device\": 1,\n",
    "    \"optimizer\": {\n",
    "      \"type\": \"huggingface_adamw\",\n",
    "      \"lr\": LR\n",
    "    },\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile models/tune_label_predictor.sh\n",
    "\n",
    "export METHOD=label_predictor_bimpm\n",
    "export STUDY_NAME=label_tuning_1\n",
    "mkdir optuna\n",
    "rm -r optuna/$METHOD\n",
    "mkdir optuna/$METHOD\n",
    "\n",
    "allennlp tune ${METHOD}/config_elmo_fasttext.jsonnet label_bimpm_params.json --serialization-dir optuna/$METHOD \\\n",
    "    --study-name $STUDY_NAME \\\n",
    "    --skip-if-exists \\\n",
    "    --metrics best_validation_f1_macro \\\n",
    "    --direction maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "collect_optuna_results('models/optuna/label_predictor_bimpm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(sorted([0.40781721303408797, 0.3998988602649082, 0.4202644174749201, 0.41427419673312793, 0.37974115122448315,\n",
    "           0.4106660695238547, 0.41931628300385043, 0.40962370891462674, 0.4246042018586939, 0.4083355727859519,\n",
    "           0.424028525298292])).plot(kind='density', bw_method=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(sorted([0.40781721303408797, 0.3998988602649082, 0.4202644174749201, 0.41427419673312793, \n",
    "                  0.37974115122448315, 0.4106660695238547, 0.41931628300385043, 0.40962370891462674, \n",
    "                  0.4246042018586939, 0.4083355727859519, 0.424028525298292])).plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! cd models && allennlp best-params --study-name label_tuning_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! rm -r models/label_predictor_bimpm/elmo_ft/\n",
    "! mv models/optuna/label_predictor_bimpm/trial_19 models/label_predictor_bimpm/elmo_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Scripts for training/prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Option 1. Directly from the config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile models/train_label_predictor.sh\n",
    "# usage:\n",
    "# $ cd models \n",
    "# $ sh train_label_predictor.sh {bert|elmo} result_30\n",
    "\n",
    "export METHOD=${1}\n",
    "export RESULT_DIR=${2}\n",
    "export DEV_FILE_PATH=\"nlabel_cf_dev.tsv\"\n",
    "export TEST_FILE_PATH=\"nlabel_cf_test.tsv\"\n",
    "\n",
    "rm -r label_predictor_bimpm/${RESULT_DIR}/\n",
    "allennlp train -s label_predictor_bimpm/${RESULT_DIR}/ label_predictor_bimpm/config_${METHOD}.json \\\n",
    "    --include-package customization_package\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_bimpm/${RESULT_DIR}/predictions_dev.json label_predictor_bimpm/${RESULT_DIR}/model.tar.gz label_predictor_bimpm/${DEV_FILE_PATH} \\\n",
    "    --include-package customization_package \\\n",
    "    --predictor textual-entailment\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_bimpm/${RESULT_DIR}/predictions_test.json label_predictor_bimpm/${RESULT_DIR}/model.tar.gz label_predictor_bimpm/${TEST_FILE_PATH} \\\n",
    "    --include-package customization_package \\\n",
    "    --predictor textual-entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Predict on dev&test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile models/eval_label_predictor.sh\n",
    "# usage:\n",
    "# $ cd models \n",
    "# $ sh train_label_predictor.sh {bert|elmo}\n",
    "\n",
    "export RESULT_DIR=${1}\n",
    "export DEV_FILE_PATH=\"nlabel_cf_dev.tsv\"\n",
    "export TEST_FILE_PATH=\"nlabel_cf_test.tsv\"\n",
    "\n",
    "allennlp predict --use-dataset-reader --cuda-device 0 --silent \\\n",
    "    --output-file label_predictor_bimpm/${RESULT_DIR}/predictions_dev.json label_predictor_bimpm/${RESULT_DIR}/model.tar.gz label_predictor_bimpm/${DEV_FILE_PATH} \\\n",
    "    --include-package bimpm_custom_package \n",
    "allennlp predict --use-dataset-reader --cuda-device 0 --silent \\\n",
    "    --output-file label_predictor_bimpm/${RESULT_DIR}/predictions_test.json label_predictor_bimpm/${RESULT_DIR}/model.tar.gz label_predictor_bimpm/${TEST_FILE_PATH} \\\n",
    "    --include-package bimpm_custom_package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(optional) predict on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile models/eval_label_predictor_train.sh\n",
    "# usage:\n",
    "# $ cd models \n",
    "# $ sh eval_label_predictor_train.sh {bert|elmo} result_30\n",
    "\n",
    "export METHOD=${1}\n",
    "export RESULT_DIR=${2}\n",
    "export TEST_FILE_PATH=\"nlabel_cf_train.tsv\"\n",
    "\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_bimpm/${RESULT_DIR}/predictions_train.json label_predictor_bimpm/${RESULT_DIR}/model.tar.gz label_predictor_bimpm/${TEST_FILE_PATH} \\\n",
    "    --include-package customization_package \\\n",
    "    --predictor textual-entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Option 2 (OLD!). Using wandb for parameters adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile models/wandb_label_predictor1.yaml\n",
    "\n",
    "name: label_predictor_stacked\n",
    "program: wandb_allennlp # this is a wrapper console script around allennlp commands. It is part of wandb-allennlp\n",
    "method: bayes\n",
    "## Do not for get to use the command keyword to specify the following command structure\n",
    "command:\n",
    "  - ${program} #omit the interpreter as we use allennlp train command directly\n",
    "  - \"--subcommand=train\"\n",
    "  - \"--include-package=bimpm_custom_package\" # add all packages containing your registered classes here\n",
    "  - \"--config_file=label_predictor_bimpm/config_elmo.json\"\n",
    "  - ${args}\n",
    "metric:\n",
    "    name: best_f1_macro\n",
    "    goal: maximize\n",
    "parameters:\n",
    "    iterator.batch_size:\n",
    "        values: [4,]\n",
    "    model.encode_together:\n",
    "        values: [\"true\", ]\n",
    "    trainer.optimizer.lr:\n",
    "        values: [0.001,]\n",
    "    model.dropout:\n",
    "        values: [0.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile models/wandb_label_predictor2.yaml\n",
    "\n",
    "name: label_predictor_stacked\n",
    "program: wandb_allennlp # this is a wrapper console script around allennlp commands. It is part of wandb-allennlp\n",
    "method: bayes\n",
    "## Do not for get to use the command keyword to specify the following command structure\n",
    "command:\n",
    "  - ${program} #omit the interpreter as we use allennlp train command directly\n",
    "  - \"--subcommand=train\"\n",
    "  - \"--include-package=bimpm_custom_package\" # add all packages containing your registered classes here\n",
    "  - \"--config_file=label_predictor_bimpm/config_elmo_fasttext.json\"\n",
    "  - ${args}\n",
    "metric:\n",
    "    name: best_f1_macro\n",
    "    goal: maximize\n",
    "parameters:\n",
    "    iterator.batch_size:\n",
    "        values: [4,]\n",
    "    model.encode_together:\n",
    "        values: [\"true\", ]\n",
    "    trainer.optimizer.lr:\n",
    "        values: [0.001,]\n",
    "    model.dropout:\n",
    "        values: [0.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! rm -r ../../../maintenance_rst/models/label_predictor_bimpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! cp -r models/label_predictor_bimpm ../../../maintenance_rst/models/label_predictor_bimpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. Run training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "``wandb sweep wandb_label_predictor1.yaml``\n",
    "\n",
    "(returns %sweepname1)\n",
    "\n",
    "``wandb sweep wandb_label_predictor2.yaml``\n",
    "\n",
    "(returns %sweepname2)\n",
    "\n",
    "``wandb agent --count 1 %sweepname1 && wandb agent --count 1 %sweepname2``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Move the best model in label_predictor_bimpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! ls -laht models/wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! cp -r models/wandb/run-20200721_172146-kggsduvw/training_dumps models/label_predictor_bimpm/noble-sweep-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Or** load from wandb by %sweepname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "api = wandb.Api()\n",
    "run = api.run(\"tchewik/tmp/7hum4oom\")\n",
    "for file in run.files():\n",
    "    file.download(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! cp -r training_dumps models/label_predictor_bimpm/toasty-sweep-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And run evaluation from shell\n",
    "\n",
    "``sh eval_label_predictor.sh {elmo|elmo_fasttext} toasty-sweep-1``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_predictions(path):\n",
    "    result = []\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            result.append(json.loads(line)[\"label\"])\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RESULT_DIR = 'elmo_ft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = '../../models/label_predictor_bimpm/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "true = pd.read_csv(DEV_FILE_PATH, sep='\\t', header=None)[0].values.tolist()\n",
    "pred = load_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_dev.json')\n",
    "\n",
    "print('length of true:', len(true))\n",
    "print('length of pred:', len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(true[:len(pred)], pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_metrics = classification_report(true[:len(pred)], pred, digits=4, output_dict=True)\n",
    "test_f1 = np.array(\n",
    "    [test_metrics[label].get('f1-score') for label in test_metrics if type(test_metrics[label]) == dict]) * 100\n",
    "\n",
    "test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(true[:len(pred)], pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils.plot_confusion_matrix import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = list(set(true))\n",
    "labels.sort()\n",
    "plot_confusion_matrix(confusion_matrix(true[:len(pred)], pred), target_names=labels, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "high_level_relations = {\n",
    "    'coherence': ['background', 'elaboration', 'restatement', 'interpretation-evaluation', 'preparation',\n",
    "                  'solutionhood'],\n",
    "    'causal-argumentative:contrastive': ['concession', 'contrast', 'comparison'],\n",
    "    'causal-argumentative:causal': ['purpose', 'evidence', 'cause-effect'],\n",
    "    'causal-argumentative:condition': ['condition'],\n",
    "    'structural': ['sequence', 'joint', 'same-unit'],\n",
    "    'attribution': ['attribution']\n",
    "}\n",
    "\n",
    "class_mapper = dict()\n",
    "for key in high_level_relations:\n",
    "    for value in high_level_relations[key]:\n",
    "        for order in ['NN', 'NS', 'SN']:\n",
    "            class_mapper[value + '_' + order] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "true = [class_mapper.get(value) if class_mapper.get(value) else value for value in true]\n",
    "pred = [class_mapper.get(value) if class_mapper.get(value) else value for value in pred]\n",
    "\n",
    "pred_mapper = {\n",
    "    'other_NN': 'joint_NN',\n",
    "    'other_NS': 'joint_NN',\n",
    "    'other_SN': 'joint_NN'\n",
    "}\n",
    "\n",
    "pred = [pred_mapper.get(value) if pred_mapper.get(value) else value for value in pred]\n",
    "_to_stay = (np.array(true) != 'other_NN') & (np.array(true) != 'other_SN') & (np.array(true) != 'other_NS')\n",
    "\n",
    "_true = np.array(true)[_to_stay]\n",
    "_pred = np.array(pred)[_to_stay[:len(pred)]]\n",
    "labels = list(set(_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(true[:len(pred)], pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(_true[:len(_pred)], _pred), target_names=labels, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for rel in np.unique(_true):\n",
    "    print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On train set (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "true = pd.read_csv('models/label_predictor_bimpm/nlabel_cf_train.tsv', sep='\\t', header=None)[0].values.tolist()\n",
    "pred = load_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_train.json')\n",
    "\n",
    "print(classification_report(true[:len(pred)], pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file = 'models/label_predictor_lstm/nlabel_cf_train.tsv'\n",
    "true_train = pd.read_csv(file, sep='\\t', header=None)\n",
    "true_train['predicted_relation'] = pred\n",
    "\n",
    "print(true_train[true_train.relation != true_train.predicted_relation].shape)\n",
    "\n",
    "true_train[true_train.relation != true_train.predicted_relation].to_csv('mispredicted_relations.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "true = pd.read_csv(TEST_FILE_PATH, sep='\\t', header=None)[0].values.tolist()\n",
    "pred = load_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_test.json')\n",
    "\n",
    "print('length of true:', len(true))\n",
    "print('length of pred:', len(pred))\n",
    "\n",
    "print(classification_report(true[:len(pred)], pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_metrics = classification_report(true[:len(pred)], pred, digits=4, output_dict=True)\n",
    "test_f1 = np.array(\n",
    "    [test_metrics[label].get('f1-score') for label in test_metrics if type(test_metrics[label]) == dict]) * 100\n",
    "\n",
    "test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(true[:len(pred)], pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "true = [class_mapper.get(value) if class_mapper.get(value) else value for value in true]\n",
    "pred = [class_mapper.get(value) if class_mapper.get(value) else value for value in pred]\n",
    "pred = [pred_mapper.get(value) if pred_mapper.get(value) else value for value in pred]\n",
    "\n",
    "_to_stay = (np.array(true) != 'other_NN') & (np.array(true) != 'other_SN') & (np.array(true) != 'other_NS')\n",
    "\n",
    "_true = np.array(true)[_to_stay]\n",
    "_pred = np.array(pred)[_to_stay]\n",
    "\n",
    "\n",
    "print('f1: %.2f'%(f1_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "\n",
    "print(classification_report(_true[:len(_pred)], _pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(_true[:len(_pred)], _pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ensemble: (Logreg+Catboost) + BiMPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_vocab = [\n",
    "    \"joint_NN\",\n",
    "    \"elaboration_NS\",\n",
    "    \"contrast_NN\",\n",
    "    \"attribution_SN\",\n",
    "    \"interpretation-evaluation_NS\",\n",
    "    \"cause-effect_SN\",\n",
    "    \"preparation_SN\",\n",
    "    \"sequence_NN\",\n",
    "    \"cause-effect_NS\",\n",
    "    \"same-unit_NN\",\n",
    "    \"condition_SN\",\n",
    "    \"purpose_NS\",\n",
    "    \"attribution_NS\",\n",
    "    \"condition_NS\",\n",
    "    \"comparison_NN\",\n",
    "    \"background_NS\",\n",
    "    \"evidence_NS\",\n",
    "    \"solutionhood_SN\",\n",
    "    \"concession_NS\",\n",
    "    \"interpretation-evaluation_SN\",\n",
    "    \"restatement_NN\",\n",
    "    \"purpose_SN\",\n",
    "]\n",
    "\n",
    "catboost_vocab = [\n",
    "    'attribution_NS', 'attribution_SN', 'background_NS',\n",
    "    'cause-effect_NS', 'cause-effect_SN', 'comparison_NN',\n",
    "    'concession_NS', 'condition_NS', 'condition_SN', 'contrast_NN',\n",
    "    'elaboration_NS', 'evidence_NS', 'interpretation-evaluation_NS',\n",
    "    'interpretation-evaluation_SN', 'joint_NN', 'preparation_SN',\n",
    "    'purpose_NS', 'purpose_SN', 'restatement_NN', 'same-unit_NN',\n",
    "    'sequence_NN', 'solutionhood_SN']\n",
    "\n",
    "def load_neural_predictions(path):\n",
    "    result = []\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            probs = json.loads(line)['probs']\n",
    "            probs = {model_vocab[i]: probs[i] for i in range(len(model_vocab))}\n",
    "            result.append(probs)\n",
    "            \n",
    "    return result\n",
    "\n",
    "def load_scikit_predictions(model, X):\n",
    "    result = []\n",
    "    predictions = model.predict_proba(X)\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        probs = {catboost_vocab[j]: prediction[j] for j in range(len(catboost_vocab))}\n",
    "        result.append(probs)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def vote_predictions(pred1, pred2, soft=True, weights=[1., 1.]):\n",
    "    assert len(pred1) == len(pred2)\n",
    "    result = []\n",
    "    \n",
    "    for i in range(len(pred1)):\n",
    "        sample_result = {}\n",
    "        for key in pred1[i].keys():\n",
    "            if soft:\n",
    "                sample_result[key] = pred1[i][key]*weights[0] + pred2[i][key]*weights[1]\n",
    "            else:\n",
    "                sample_result[key] = max(pred1[i][key], pred2[i][key])\n",
    "        \n",
    "        result.append(sample_result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def probs_to_classes(pred):\n",
    "    result = []\n",
    "    result_proba = []\n",
    "    \n",
    "    for sample in pred:\n",
    "        best_class = ''\n",
    "        best_prob = 0.\n",
    "        for key in sample.keys():\n",
    "            if sample[key] > best_prob:\n",
    "                best_prob = sample[key]\n",
    "                best_class = key\n",
    "        \n",
    "        result.append(best_class)\n",
    "        result_proba.append(best_prob)\n",
    "    \n",
    "    return result, result_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "baseline_model_path = '../../models/label_predictor_baseline/'\n",
    "fs_catboost_plus_logreg = pickle.load(open(os.path.join(baseline_model_path, 'model.pkl'), 'rb'))\n",
    "lab_encoder = pickle.load(open(os.path.join(baseline_model_path, 'label_encoder.pkl'), 'rb'))\n",
    "scaler = pickle.load(open(os.path.join(baseline_model_path, 'scaler.pkl'), 'rb'))\n",
    "drop_columns = pickle.load(open(os.path.join(baseline_model_path, 'drop_columns.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "TARGET = 'relation'\n",
    "\n",
    "y_dev, X_dev = dev_samples['relation'].to_frame(), dev_samples.drop('relation', axis=1).drop(\n",
    "    columns=drop_columns + ['category_id', 'index'])\n",
    "\n",
    "for additional_col in ('pred_category', 'true_category', 'pred_relation', 'pred_proba'):\n",
    "    if additional_col in X_dev.keys():\n",
    "        X_dev = X_dev.drop(columns=[additional_col])\n",
    "\n",
    "X_scaled_np = scaler.transform(X_dev)\n",
    "X_dev = pd.DataFrame(X_scaled_np, index=X_dev.index)\n",
    "\n",
    "catboost_predictions = load_scikit_predictions(fs_catboost_plus_logreg, X_dev)\n",
    "neural_predictions = load_neural_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp = vote_predictions(neural_predictions, catboost_predictions, soft=True, weights=[.3, .8])\n",
    "ensemble_pred, _ = probs_to_classes(tmp)\n",
    "\n",
    "print('weighted f1: ', metrics.f1_score(y_dev.values, ensemble_pred, average='weighted'))\n",
    "print('macro f1: ', metrics.f1_score(y_dev.values, ensemble_pred, average='macro'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_dev.values, ensemble_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_dev, ensemble_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dev_samples['pred_relation'] = ensemble_pred\n",
    "dev_samples['pred_proba'] = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_dev.values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Blending coeffs\n",
    "\n",
    "macro_f1 = 0.0\n",
    "for w0 in np.arange(0.1, 1., 0.1):\n",
    "    for w1 in np.arange(0.1, 1., 0.1):\n",
    "        tmp = vote_predictions(neural_predictions, catboost_predictions, soft=True, weights=[w0, w1])\n",
    "        ensemble_pred, _ = probs_to_classes(tmp)\n",
    "        new_macro_f1 = metrics.f1_score(y_dev.values, ensemble_pred, average='macro')\n",
    "        if new_macro_f1 > macro_f1:\n",
    "            print(w0, w1, new_macro_f1)\n",
    "            macro_f1 = new_macro_f1\n",
    "#         print(new_macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "true = [value[0] for value in y_dev.values]\n",
    "true = [class_mapper.get(value) if class_mapper.get(value) else value for value in true]\n",
    "ensemble_pred = [class_mapper.get(value) if class_mapper.get(value) else value for value in ensemble_pred]\n",
    "ensemble_pred = [pred_mapper.get(value) if pred_mapper.get(value) else value for value in ensemble_pred]\n",
    "\n",
    "_to_stay = (np.array(true) != 'other_NN') & (np.array(true) != 'other_SN') & (np.array(true) != 'other_NS')\n",
    "\n",
    "_true = np.array(true)[_to_stay]\n",
    "_pred = np.array(ensemble_pred)[_to_stay]\n",
    "\n",
    "\n",
    "print('f1: %.2f'%(f1_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "\n",
    "print(classification_report(_true[:len(_pred)], _pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dev_samples['pred_category'] = _pred\n",
    "dev_samples['true_category'] = _true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TARGET = 'relation'\n",
    "\n",
    "y_test, X_test = test_samples[TARGET].to_frame(), test_samples.drop(TARGET, axis=1).drop(\n",
    "    columns=drop_columns + ['category_id', 'index'])\n",
    "\n",
    "for additional_col in ('pred_category', 'true_category', 'pred_relation'):\n",
    "    if additional_col in X_test.keys():\n",
    "        X_test = X_test.drop(columns=[additional_col])\n",
    "\n",
    "X_scaled_np = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_scaled_np, index=X_test.index)\n",
    "\n",
    "catboost_predictions = load_scikit_predictions(fs_catboost_plus_logreg, X_test)\n",
    "neural_predictions = load_neural_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_test.json')\n",
    "\n",
    "tmp = vote_predictions(neural_predictions, catboost_predictions, soft=True, weights=[.3, .8])\n",
    "\n",
    "ensemble_pred, proba = probs_to_classes(tmp)\n",
    "\n",
    "print('weighted f1: ', metrics.f1_score(y_test.values, ensemble_pred, average='weighted'))\n",
    "print('macro f1: ', metrics.f1_score(y_test.values, ensemble_pred, average='macro'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_test.values, ensemble_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, ensemble_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_samples['pred_relation'] = ensemble_pred\n",
    "test_samples['pred_proba'] = proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_metrics = classification_report(y_test, ensemble_pred, digits=4, output_dict=True)\n",
    "test_f1 = np.array(\n",
    "    [test_metrics[label].get('f1-score') for label in test_metrics if type(test_metrics[label]) == dict]) * 100\n",
    "\n",
    "test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "true = [value[0] for value in y_test.values]\n",
    "true = [class_mapper.get(value) if class_mapper.get(value) else value for value in true]\n",
    "ensemble_pred = [class_mapper.get(value) if class_mapper.get(value) else value for value in ensemble_pred]\n",
    "ensemble_pred = [pred_mapper.get(value) if pred_mapper.get(value) else value for value in ensemble_pred]\n",
    "\n",
    "_to_stay = (np.array(true) != 'other_NN') & (np.array(true) != 'other_SN') & (np.array(true) != 'other_NS')\n",
    "\n",
    "_true = np.array(true)[_to_stay]\n",
    "_pred = np.array(ensemble_pred)[_to_stay]\n",
    "\n",
    "\n",
    "print('f1: %.2f'%(f1_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "\n",
    "print(classification_report(_true[:len(_pred)], _pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = list(set(_true))\n",
    "labels.sort()\n",
    "plot_confusion_matrix(confusion_matrix(_true[:len(_pred)], _pred), target_names=labels, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_samples['pred_category'] = _pred\n",
    "test_samples['true_category'] = _true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_samples[(test_samples.pred_category != test_samples.true_category) & (\n",
    "              test_samples.true_category == 'causal-argumentative:causal') & (\n",
    "              test_samples.filename.str.startswith('depression.'))][['snippet_x', 'snippet_y', \n",
    "                                                                     'relation', 'true_category', \n",
    "                                                                     'pred_relation', 'pred_category']].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Compare results for RuRSTreebank and Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_data = test_samples[test_samples.filename.str.contains('blogs') | test_samples.filename.str.contains('news')]\n",
    "_true = _data.true_category.values.tolist()\n",
    "_pred = _data.pred_category.values.tolist()\n",
    "\n",
    "_data = dev_samples[test_samples.filename.str.contains('blogs') | dev_samples.filename.str.contains('news')]\n",
    "_true += _data.true_category.values.tolist()\n",
    "_pred += _data.pred_category.values.tolist()\n",
    "\n",
    "print('f1: %.2f'%(f1_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "\n",
    "print(classification_report(_true[:len(_pred)], _pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_data = test_samples[test_samples.filename.str.contains('depression.') | test_samples.filename.str.contains('healthy.')]\n",
    "_true = _data.true_category.values.tolist()\n",
    "_pred = _data.pred_category.values.tolist()\n",
    "\n",
    "_data = dev_samples[test_samples.filename.str.contains('depression.') | dev_samples.filename.str.contains('healthy.')]\n",
    "_true += _data.true_category.values.tolist()\n",
    "_pred += _data.pred_category.values.tolist()\n",
    "\n",
    "print('f1: %.2f'%(f1_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "\n",
    "print(classification_report(_true[:len(_pred)], _pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = list(set(_true))\n",
    "labels.sort()\n",
    "plot_confusion_matrix(confusion_matrix(_true[:len(_pred)], _pred), target_names=labels, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Just for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from allennlp.predictors.predictor import Predictor\n",
    "\n",
    "# predictor_name='textual_entailment'\n",
    "# clf.predict(premise='Сейчас я думаю,', hypothesis='что')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}