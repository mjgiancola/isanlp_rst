{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Rhetorical relations classification used in tree building: Step 2. Feature-rich approach\n",
    "\n",
    "Train models, save the best one.\n",
    "\n",
    "Output:\n",
    " - ``models/relation_predictor_baseline/*``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import Pool\n",
    "from matplotlib import rcParams\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import column_or_1d\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['font.sans-serif'] = 'Arial'\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "random_state = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! mkdir models/relation_predictor_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Memorize useless data fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-mEy6IbWs7K",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IN_PATH = 'data_labeling'\n",
    "\n",
    "train_samples = pd.read_pickle(os.path.join(IN_PATH, 'train_samples.pkl'))\n",
    "dev_samples = pd.read_pickle(os.path.join(IN_PATH, 'dev_samples.pkl'))\n",
    "test_samples = pd.read_pickle(os.path.join(IN_PATH, 'test_samples.pkl'))\n",
    "    \n",
    "df = pd.concat([train_samples, dev_samples, test_samples])\n",
    "df = df.fillna(0.)\n",
    "\n",
    "constants = [c for c in df.drop(columns=['tokens_x', 'tokens_y']).columns if len(set(df[c])) == 1]\n",
    "to_drop = ['snippet_x', 'snippet_y', 'snippet_x_tmp', 'snippet_y_tmp', 'filename', 'order', 'postags_x', 'postags_y',\n",
    "           'tokens_x', 'tokens_y']\n",
    "# df = df.drop(columns=constants)\n",
    "del df\n",
    "pickle.dump(constants + to_drop, open('models/relation_predictor_baseline/drop_columns.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prepare label encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyLabelEncoder(LabelEncoder):\n",
    "\n",
    "    def fit(self, y):\n",
    "        y = column_or_1d(y, warn=True)\n",
    "        self.classes_ = pd.Series(y)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prepare train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IN_PATH = 'data_labeling'\n",
    "\n",
    "train_samples = pd.read_pickle(os.path.join(IN_PATH, 'train_samples.pkl'))\n",
    "dev_samples = pd.read_pickle(os.path.join(IN_PATH, 'dev_samples.pkl'))\n",
    "test_samples = pd.read_pickle(os.path.join(IN_PATH, 'test_samples.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "counts = train_samples['relation'].value_counts(normalize=False).values\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_samples.relation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop_columns = pickle.load(open('models/relation_predictor_baseline/drop_columns.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train, _X_train = train_samples['relation'].to_frame(), train_samples.drop('relation', axis=1).drop(\n",
    "    columns=drop_columns + ['category_id'])\n",
    "y_dev, _X_dev = dev_samples['relation'].to_frame(), dev_samples.drop('relation', axis=1).drop(\n",
    "    columns=drop_columns + ['category_id'])\n",
    "y_test, _X_test = test_samples['relation'].to_frame(), test_samples.drop('relation', axis=1).drop(\n",
    "    columns=drop_columns + ['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(_X_train)\n",
    "\n",
    "X_scaled_np = scaler.transform(_X_train)\n",
    "X_train = pd.DataFrame(X_scaled_np, index=_X_train.index)#, columns=X.columns)\n",
    "\n",
    "X_scaled_np = scaler.transform(_X_dev)\n",
    "X_dev = pd.DataFrame(X_scaled_np, index=_X_dev.index)#, columns=X.columns)\n",
    "\n",
    "X_scaled_np = scaler.transform(_X_test)\n",
    "X_test = pd.DataFrame(X_scaled_np, index=_X_test.index)#, columns=X.columns)\n",
    "\n",
    "pickle.dump(scaler, open('models/relation_predictor_baseline/scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lab_encoder = LabelEncoder()\n",
    "y_train = lab_encoder.fit_transform(y_train)\n",
    "# y_dev = lab_encoder.transform(y_dev)\n",
    "pickle.dump(lab_encoder, open('models/relation_predictor_baseline/label_encoder.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_dataset = Pool(data=X_dev,\n",
    "                    label=y_dev)\n",
    "\n",
    "catboost = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    custom_loss=['F1'],\n",
    "    random_seed=random_state,\n",
    "    verbose=2,\n",
    "    loss_function='MultiClass',\n",
    "    class_weights=counts / counts[-1],\n",
    "    eval_metric='TotalF1'\n",
    ")\n",
    "\n",
    "\n",
    "fs_catboost = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LogisticRegression(penalty='l1', solver='saga', C=1., n_jobs=-1))),\n",
    "  ('classification', catboost)\n",
    "])\n",
    "\n",
    "logreg = LogisticRegression(random_state=random_state,\n",
    "                            solver='lbfgs',\n",
    "                            n_jobs=-1,\n",
    "                            C=0.002,\n",
    "                            multi_class='multinomial',\n",
    "                            class_weight='balanced')\n",
    "\n",
    "fs_catboost_plus_logreg = VotingClassifier(\n",
    "    [('fs_catboost', fs_catboost), ('logreg', logreg)], voting='soft', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fs_catboost_plus_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(fs_catboost_plus_logreg, open('models/relation_predictor_baseline/model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load & predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fs_catboost_plus_logreg = pickle.load(open('models/relation_predictor_baseline/model.pkl', 'rb'))\n",
    "lab_encoder = pickle.load(open('models/relation_predictor_baseline/label_encoder.pkl', 'rb'))\n",
    "scaler = pickle.load(open('models/relation_predictor_baseline/scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. (Optional) Explore the feature importances in case we could clean up some vocabularies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First estimator in a pipeline, L1 logreg, will show us the features used in no way in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lg1 = fs_catboost_plus_logreg.estimators_[0].steps[0][1]\n",
    "lg1_filtered = [feature for feature in X_dev.keys() if not feature in lg1.get_feature_names_out(input_features = X_dev.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(lg1_filtered), lg1_filtered  # Look at them, clean up the feature extractor's vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second estimator, CatBoost, and it's feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fil = pd.DataFrame({\n",
    "    'feature': lg1.get_feature_names_out(input_features = _X_dev.keys()),\n",
    "    'f': fs_catboost_plus_logreg.estimators_[0].steps[1][1].feature_importances_\n",
    "})\n",
    "\n",
    "fil.sort_values('f', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fil[fil.f == 0].feature.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_scaled_np = scaler.transform(_X_dev)\n",
    "X_dev = pd.DataFrame(X_scaled_np, index=_X_dev.index)#, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted = lab_encoder.inverse_transform(fs_catboost_plus_logreg.predict(X_dev))\n",
    "\n",
    "print('weighted f1: ', metrics.f1_score(y_dev.values, predicted, average='weighted'))\n",
    "print('macro f1: ', metrics.f1_score(y_dev.values, predicted, average='macro'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_dev.values, predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_dev, predicted, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_scaled_np = scaler.transform(_X_test)\n",
    "X_test = pd.DataFrame(X_scaled_np, index=_X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted = lab_encoder.inverse_transform(fs_catboost_plus_logreg.predict(X_test))\n",
    "\n",
    "print('weighted f1: ', metrics.f1_score(y_test.values, predicted, average='weighted'))\n",
    "print('macro f1: ', metrics.f1_score(y_test.values, predicted, average='macro'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_test.values, predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predicted, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_metrics = metrics.classification_report(y_test, predicted, digits=4, output_dict=True)\n",
    "test_f1 = np.array(\n",
    "    [test_metrics[label].get('f1-score') for label in test_metrics if type(test_metrics[label]) == dict]) * 100\n",
    "\n",
    "test_f1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "XL9qxhZeGdB1",
    "EAiXKY8dnxQs",
    "-WGdV8VGcJUt",
    "WNGYIPB0cPdW",
    "WMD4jEJScaFy",
    "9idVoMLIBytW"
   ],
   "name": "experiments_ml.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}