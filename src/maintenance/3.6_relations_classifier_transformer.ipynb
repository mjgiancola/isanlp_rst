{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhetorical relations classification used in tree building: Transformer\n",
    "\n",
    "Prepare data and model-related scripts.\n",
    "\n",
    "Evaluate models.\n",
    "\n",
    "Make and evaluate ansembles for Transformer-based and feature-based model.\n",
    "\n",
    "Output:\n",
    " - ``models/relation_predictor_transf/*``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from utils.file_reading import read_edus, read_gold, read_negative, read_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models/relation_predictor_transf'\n",
    "if not os.path.isdir(MODEL_PATH):\n",
    "    os.mkdir(MODEL_PATH)\n",
    "\n",
    "TRAIN_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_train.json')\n",
    "DEV_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_dev.json')\n",
    "TEST_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train/test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_PATH = 'data_labeling'\n",
    "\n",
    "train_samples = pd.read_pickle(os.path.join(IN_PATH, 'train_samples.pkl'))\n",
    "dev_samples = pd.read_pickle(os.path.join(IN_PATH, 'dev_samples.pkl'))\n",
    "test_samples = pd.read_pickle(os.path.join(IN_PATH, 'test_samples.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel\n",
    "\n",
    "def tokenize(text):\n",
    "    result = ' '.join([tok.text for tok in razdel.tokenize(text)])\n",
    "    return result\n",
    "    \n",
    "train_samples['snippet_x'] = train_samples.snippet_x.map(tokenize)\n",
    "train_samples['snippet_y'] = train_samples.snippet_y.map(tokenize)\n",
    "\n",
    "dev_samples['snippet_x'] = dev_samples.snippet_x.map(tokenize)\n",
    "dev_samples['snippet_y'] = dev_samples.snippet_y.map(tokenize)\n",
    "\n",
    "test_samples['snippet_x'] = test_samples.snippet_x.map(tokenize)\n",
    "test_samples['snippet_y'] = test_samples.snippet_y.map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame({\n",
    "    'premise': train_samples.snippet_x,\n",
    "    'hypothesis': train_samples.snippet_y,\n",
    "    'label': train_samples.relation,\n",
    "    'idx': train_samples.index\n",
    "})\n",
    "\n",
    "dev = pd.DataFrame({\n",
    "    'premise': dev_samples.snippet_x,\n",
    "    'hypothesis': dev_samples.snippet_y,\n",
    "    'label': dev_samples.relation,\n",
    "    'idx': dev_samples.index\n",
    "})\n",
    "\n",
    "test = pd.DataFrame({\n",
    "    'premise': test_samples.snippet_x,\n",
    "    'hypothesis': test_samples.snippet_y,\n",
    "    'label': test_samples.relation,\n",
    "    'idx': test_samples.index\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# For transformer_superglue_rte data reader\n",
    "\n",
    "with open(TRAIN_FILE_PATH, 'w') as fp:\n",
    "    fp.write('\\n'.join(json.dumps(i) for i in train.to_dict('records')) + '\\n')\n",
    "\n",
    "with open(DEV_FILE_PATH, 'w') as fp:\n",
    "    fp.write('\\n'.join(json.dumps(i) for i in dev.to_dict('records')) + '\\n')\n",
    "    \n",
    "with open(TEST_FILE_PATH, 'w') as fp:\n",
    "    fp.write('\\n'.join(json.dumps(i) for i in test.to_dict('records')) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models/relation_predictor_transf/config_rubert.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $MODEL_PATH/config_rubert.json\n",
    "\n",
    "local transformer_model = \"DeepPavlov/rubert-base-cased\";\n",
    "local transformer_dim = 768;\n",
    "\n",
    "local epochs = 20;\n",
    "local gpu_batch_size = 2;\n",
    "local gradient_accumulation_steps = 16;\n",
    "\n",
    "{\n",
    "  \"dataset_reader\":{\n",
    "    \"type\": \"transformer_superglue_rte\"\n",
    "  },\n",
    "  \"train_data_path\": \"relation_predictor_transf/nlabel_cf_train.json\",\n",
    "  \"validation_data_path\": \"relation_predictor_transf/nlabel_cf_dev.json\",\n",
    "  \"test_data_path\": \"relation_predictor_transf/nlabel_cf_test.json\",\n",
    "  \"model\": {\n",
    "    \"type\": \"basic_classifier\",\n",
    "    \"text_field_embedder\": {\n",
    "      \"token_embedders\": {\n",
    "        \"tokens\": {\n",
    "          \"type\": \"pretrained_transformer\",\n",
    "          \"model_name\": transformer_model,\n",
    "          \"max_length\": 512\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"seq2vec_encoder\": {\n",
    "       \"type\": \"cls_pooler\",\n",
    "       \"embedding_dim\": transformer_dim,\n",
    "    },\n",
    "    \"feedforward\": {\n",
    "      \"input_dim\": transformer_dim,\n",
    "      \"num_layers\": 1,\n",
    "      \"hidden_dims\": transformer_dim,\n",
    "      \"activations\": \"tanh\"\n",
    "    },\n",
    "    \"dropout\": 0.1,\n",
    "    \"namespace\": \"tags\"\n",
    "  },\n",
    "  \"data_loader\": {\n",
    "    \"shuffle\": true,\n",
    "    \"batch_size\": gpu_batch_size\n",
    "  },\n",
    "  \"trainer\": {\n",
    "    \"optimizer\": {\n",
    "      \"type\": \"huggingface_adamw\",\n",
    "      \"weight_decay\": 0.01,\n",
    "      \"parameter_groups\": [[[\"bias\", \"LayerNorm\\\\.weight\", \"layer_norm\\\\.weight\"], {\"weight_decay\": 0}]],\n",
    "      \"lr\": 1e-6,\n",
    "      \"eps\": 1e-8,\n",
    "      \"correct_bias\": true\n",
    "    },\n",
    "    \"learning_rate_scheduler\": {\n",
    "      \"type\": \"linear_with_warmup\",\n",
    "      \"warmup_steps\": 100\n",
    "    },\n",
    "    // \"grad_norm\": 1.0,\n",
    "    \"num_epochs\": epochs,\n",
    "    \"num_gradient_accumulation_steps\": gradient_accumulation_steps,\n",
    "    \"patience\": 5,\n",
    "    \"cuda_device\": 0,\n",
    "    \"validation_metric\": \"+accuracy\",\n",
    "  },\n",
    "  \"random_seed\": 42,\n",
    "  \"numpy_seed\": 42,\n",
    "  \"pytorch_seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models/relation_predictor_transf/config_rubert.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $MODEL_PATH/config_rubert.json\n",
    "\n",
    "local transformer_model = \"DeepPavlov/rubert-base-cased\";\n",
    "local transformer_dim = 768;\n",
    "\n",
    "local epochs = 100;\n",
    "local gpu_batch_size = 2;\n",
    "local gradient_accumulation_steps = 16;\n",
    "\n",
    "{\n",
    "  \"dataset_reader\":{\n",
    "    \"type\": \"transformer_superglue_rte\"\n",
    "  },\n",
    "  \"train_data_path\": \"relation_predictor_transf/nlabel_cf_train.json\",\n",
    "  \"validation_data_path\": \"relation_predictor_transf/nlabel_cf_dev.json\",\n",
    "  \"test_data_path\": \"relation_predictor_transf/nlabel_cf_test.json\",\n",
    "  \"model\": {\n",
    "    \"type\": \"bimpm_custom_package.model.custom_basic_classifier.CustomBasicClassifier\",\n",
    "    class_weights: [\n",
    "        0.03, 0.03, 0.08, 0.1, 0.12, 0.14,\n",
    "        0.14, 0.17, 0.17, 0.18, 0.19, 0.21,\n",
    "        0.23, 0.26, 0.33, 0.38, 0.39, 0.57,\n",
    "        0.78, 0.86, 0.97, 1.0],\n",
    "    \"text_field_embedder\": {\n",
    "      \"token_embedders\": {\n",
    "        \"tokens\": {\n",
    "          \"type\": \"pretrained_transformer\",\n",
    "          \"model_name\": transformer_model,\n",
    "          \"max_length\": 512\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"seq2vec_encoder\": {\n",
    "       type: \"bert_pooler\",\n",
    "       pretrained_model: $.model.text_field_embedder.token_embedders.tokens.model_name,\n",
    "       requires_grad: true,\n",
    "       dropout: 0.2,\n",
    "    },\n",
    "#     \"feedforward\": {\n",
    "#       \"input_dim\": transformer_dim,\n",
    "#       \"num_layers\": 1,\n",
    "#       \"hidden_dims\": transformer_dim,\n",
    "#       \"activations\": \"tanh\"\n",
    "#     },\n",
    "    \"dropout\": 0.5,\n",
    "    \"namespace\": \"tags\"\n",
    "  },\n",
    "  data_loader: {\n",
    "    batch_sampler: {\n",
    "      type: 'bucket',\n",
    "      batch_size: 2,\n",
    "    },\n",
    "  },\n",
    "  \"trainer\": {\n",
    "    \"optimizer\": {\n",
    "      \"type\": \"huggingface_adamw\",\n",
    "      \"weight_decay\": 0.01,\n",
    "#       \"parameter_groups\": [[[\"bias\", \"LayerNorm\\\\.weight\", \"layer_norm\\\\.weight\"], {\"weight_decay\": 0}]],\n",
    "      \"lr\": 2e-5,\n",
    "      \"eps\": 1e-8,\n",
    "      \"correct_bias\": true\n",
    "    },\n",
    "    learning_rate_scheduler: {\n",
    "      type: \"slanted_triangular\",\n",
    "      cut_frac: 0.06\n",
    "    },\n",
    "    // \"grad_norm\": 1.0,\n",
    "    \"num_epochs\": epochs,\n",
    "    num_serialized_models_to_keep: 1,\n",
    "    \"num_gradient_accumulation_steps\": gradient_accumulation_steps,\n",
    "    \"patience\": 5,\n",
    "    \"cuda_device\": 0,\n",
    "    \"validation_metric\": \"+f1_macro\",\n",
    "  },\n",
    "  \"random_seed\": 42,\n",
    "  \"numpy_seed\": 42,\n",
    "  \"pytorch_seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Scripts for training/prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models/train_relation_predictor_bert.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile models/train_relation_predictor_bert.sh\n",
    "# usage:\n",
    "# $ cd models \n",
    "# $ sh train_relation_predictor.sh rubert rubert_01\n",
    "\n",
    "export METHOD=${1}\n",
    "export RESULT_DIR=${2}\n",
    "export DEV_FILE_PATH=\"nlabel_cf_dev.json\"\n",
    "export TEST_FILE_PATH=\"nlabel_cf_test.json\"\n",
    "\n",
    "rm -r relation_predictor_transf/${RESULT_DIR}/\n",
    "allennlp train -s relation_predictor_transf/${RESULT_DIR}/ relation_predictor_transf/config_${METHOD}.json \\\n",
    "    --include-package bimpm_custom_package\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file relation_predictor_transf/${RESULT_DIR}/predictions_dev.json relation_predictor_transf/${RESULT_DIR}/model.tar.gz relation_predictor_transf/${DEV_FILE_PATH} \\\n",
    "    --include-package bimpm_custom_package \\\n",
    "    --predictor textual-entailment\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file relation_predictor_transf/${RESULT_DIR}/predictions_test.json relation_predictor_transf/${RESULT_DIR}/model.tar.gz relation_predictor_transf/${TEST_FILE_PATH} \\\n",
    "    --include-package bimpm_custom_package \\\n",
    "    --predictor textual-entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predictions(path):\n",
    "    result = []\n",
    "    vocab = []\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            line = json.loads(line)\n",
    "            if line.get(\"label\"):\n",
    "                result.append(line.get(\"label\"))\n",
    "            elif line.get(\"label_probs\"):\n",
    "                if not vocab:\n",
    "                    vocab = open(path[:path.rfind('/')] + '/vocabulary/labels.txt', 'r').readlines()\n",
    "                    vocab = [label.strip() for label in vocab]\n",
    "                \n",
    "                result.append(vocab[np.argmax(line.get(\"label_probs\"))])\n",
    "            \n",
    "    print('length of result:', len(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = 'rubert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/relation_predictor_transf/nlabel_cf_dev.json'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEV_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "dev_samples = pd.read_pickle(os.path.join(IN_PATH, 'dev_samples.pkl'))\n",
    "true = dev_samples.relation.values.tolist()\n",
    "# pred = load_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3d664a4f1ab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(true[:len(pred)], pred, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
