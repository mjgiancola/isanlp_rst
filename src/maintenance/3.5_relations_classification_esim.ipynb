{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhetorical relations classification used in tree building: ESIM\n",
    "\n",
    "Prepare data and model-related scripts.\n",
    "\n",
    "Evaluate models.\n",
    "\n",
    "Make and evaluate ansembles for ESIM and BiMPM model / ESIM and feature-based model.\n",
    "\n",
    "Output:\n",
    " - ``models/relation_predictor_esim/*``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from utils.file_reading import read_edus, read_gold, read_negative, read_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘models/label_predictor_esim’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = 'models/label_predictor_esim'\n",
    "! mkdir $MODEL_PATH\n",
    "\n",
    "TRAIN_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_train.tsv')\n",
    "DEV_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_dev.tsv')\n",
    "TEST_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_test.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train/test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_PATH = 'data_labeling'\n",
    "\n",
    "train_samples = pd.read_pickle(os.path.join(IN_PATH, 'train_samples.pkl'))\n",
    "dev_samples = pd.read_pickle(os.path.join(IN_PATH, 'dev_samples.pkl'))\n",
    "test_samples = pd.read_pickle(os.path.join(IN_PATH, 'test_samples.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 22\n",
      "class weights:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.027483, 0.032003, 0.080478, 0.102642, 0.121394, 0.135027,\n",
       "       0.136856, 0.170897, 0.172355, 0.181655, 0.193858, 0.211297,\n",
       "       0.231651, 0.260982, 0.334437, 0.378277, 0.392996, 0.567416,\n",
       "       0.782946, 0.855932, 0.971154, 1.      ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = train_samples['relation'].value_counts(normalize=False).values\n",
    "NUMBER_CLASSES = len(counts)\n",
    "print(\"number of classes:\", NUMBER_CLASSES)\n",
    "print(\"class weights:\")\n",
    "np.round(counts.min() / counts, decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train_samples['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joint_NN                        3675\n",
       "elaboration_NS                  3156\n",
       "contrast_NN                     1255\n",
       "attribution_SN                   984\n",
       "interpretation-evaluation_NS     832\n",
       "cause-effect_SN                  748\n",
       "preparation_SN                   738\n",
       "cause-effect_NS                  591\n",
       "sequence_NN                      586\n",
       "same-unit_NN                     556\n",
       "condition_SN                     521\n",
       "purpose_NS                       478\n",
       "attribution_NS                   436\n",
       "condition_NS                     387\n",
       "comparison_NN                    302\n",
       "background_NS                    267\n",
       "evidence_NS                      257\n",
       "solutionhood_SN                  178\n",
       "concession_NS                    129\n",
       "interpretation-evaluation_SN     118\n",
       "restatement_NN                   104\n",
       "purpose_SN                       101\n",
       "Name: relation, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel\n",
    "\n",
    "def tokenize(text):\n",
    "    result = ' '.join([tok.text for tok in razdel.tokenize(text)])\n",
    "    return result\n",
    "    \n",
    "train_samples['snippet_x'] = train_samples.snippet_x.map(tokenize)\n",
    "train_samples['snippet_y'] = train_samples.snippet_y.map(tokenize)\n",
    "\n",
    "dev_samples['snippet_x'] = dev_samples.snippet_x.map(tokenize)\n",
    "dev_samples['snippet_y'] = dev_samples.snippet_y.map(tokenize)\n",
    "\n",
    "test_samples['snippet_x'] = test_samples.snippet_x.map(tokenize)\n",
    "test_samples['snippet_y'] = test_samples.snippet_y.map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = train_samples.reset_index()\n",
    "train_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(TRAIN_FILE_PATH, sep='\\t', header=False, index=False)\n",
    "\n",
    "dev_samples = dev_samples.reset_index()\n",
    "dev_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(DEV_FILE_PATH, sep='\\t', header=False, index=False)\n",
    "\n",
    "test_samples = test_samples.reset_index()\n",
    "test_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(TEST_FILE_PATH, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Add F1, concatenated encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models/bimpm_custom_package/model/esim.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile models/bimpm_custom_package/model/esim.py\n",
    "\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "from allennlp.common.checks import check_dimensions_match\n",
    "from allennlp.data import TextFieldTensors, Vocabulary\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.modules import FeedForward, InputVariationalDropout\n",
    "from allennlp.modules.matrix_attention.matrix_attention import MatrixAttention\n",
    "from allennlp.modules import Seq2SeqEncoder, TextFieldEmbedder\n",
    "from allennlp.nn import InitializerApplicator\n",
    "from allennlp.nn.util import (\n",
    "    get_text_field_mask,\n",
    "    masked_softmax,\n",
    "    weighted_sum,\n",
    "    masked_max,\n",
    ")\n",
    "from allennlp.training.metrics import CategoricalAccuracy, F1Measure\n",
    "\n",
    "\n",
    "@Model.register(\"custom_esim\")\n",
    "class CustomESIM(Model):\n",
    "    \"\"\"\n",
    "    This `Model` implements the ESIM sequence model described in [Enhanced LSTM for Natural Language Inference]\n",
    "    (https://api.semanticscholar.org/CorpusID:34032948) by Chen et al., 2017.\n",
    "    Registered as a `Model` with name \"esim\".\n",
    "    # Parameters\n",
    "    vocab : `Vocabulary`\n",
    "    text_field_embedder : `TextFieldEmbedder`\n",
    "        Used to embed the `premise` and `hypothesis` `TextFields` we get as input to the\n",
    "        model.\n",
    "    encoder : `Seq2SeqEncoder`\n",
    "        Used to encode the premise and hypothesis.\n",
    "    matrix_attention : `MatrixAttention`\n",
    "        This is the attention function used when computing the similarity matrix between encoded\n",
    "        words in the premise and words in the hypothesis.\n",
    "    projection_feedforward : `FeedForward`\n",
    "        The feedforward network used to project down the encoded and enhanced premise and hypothesis.\n",
    "    inference_encoder : `Seq2SeqEncoder`\n",
    "        Used to encode the projected premise and hypothesis for prediction.\n",
    "    output_feedforward : `FeedForward`\n",
    "        Used to prepare the concatenated premise and hypothesis for prediction.\n",
    "    output_logit : `FeedForward`\n",
    "        This feedforward network computes the output logits.\n",
    "    dropout : `float`, optional (default=`0.5`)\n",
    "        Dropout percentage to use.\n",
    "    initializer : `InitializerApplicator`, optional (default=`InitializerApplicator()`)\n",
    "        Used to initialize the model parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab: Vocabulary,\n",
    "        text_field_embedder: TextFieldEmbedder,\n",
    "        encoder: Seq2SeqEncoder,\n",
    "        matrix_attention: MatrixAttention,\n",
    "        projection_feedforward: FeedForward,\n",
    "        inference_encoder: Seq2SeqEncoder,\n",
    "        output_feedforward: FeedForward,\n",
    "        output_logit: FeedForward,\n",
    "        encode_together: bool = False,\n",
    "        dropout: float = 0.5,\n",
    "        class_weights: list = [],\n",
    "        initializer: InitializerApplicator = InitializerApplicator(),\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(vocab, **kwargs)\n",
    "\n",
    "        self._text_field_embedder = text_field_embedder\n",
    "        self._encoder = encoder\n",
    "\n",
    "        self._matrix_attention = matrix_attention\n",
    "        self._projection_feedforward = projection_feedforward\n",
    "\n",
    "        self._inference_encoder = inference_encoder\n",
    "\n",
    "        if dropout:\n",
    "            self.dropout = torch.nn.Dropout(dropout)\n",
    "            self.rnn_input_dropout = InputVariationalDropout(dropout)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "            self.rnn_input_dropout = None\n",
    "\n",
    "        self._output_feedforward = output_feedforward\n",
    "        self._output_logit = output_logit\n",
    "        self.encode_together = encode_together\n",
    "\n",
    "        self._num_labels = vocab.get_vocab_size(namespace=\"labels\")\n",
    "\n",
    "        check_dimensions_match(\n",
    "            text_field_embedder.get_output_dim(),\n",
    "            encoder.get_input_dim(),\n",
    "            \"text field embedding dim\",\n",
    "            \"encoder input dim\",\n",
    "        )\n",
    "        check_dimensions_match(\n",
    "            encoder.get_output_dim() * 4,\n",
    "            projection_feedforward.get_input_dim(),\n",
    "            \"encoder output dim\",\n",
    "            \"projection feedforward input\",\n",
    "        )\n",
    "        check_dimensions_match(\n",
    "            projection_feedforward.get_output_dim(),\n",
    "            inference_encoder.get_input_dim(),\n",
    "            \"proj feedforward output dim\",\n",
    "            \"inference lstm input dim\",\n",
    "        )\n",
    "\n",
    "        self.metrics = {\"accuracy\": CategoricalAccuracy()}\n",
    "        \n",
    "        if class_weights:\n",
    "            self.class_weights = class_weights\n",
    "        else:\n",
    "            self.class_weights = [1.] * self.classifier_feedforward.get_output_dim()\n",
    "            \n",
    "        for _class in range(len(self.class_weights)):\n",
    "            self.metrics.update({\n",
    "                f\"f1_rel{_class}\": F1Measure(_class),\n",
    "            })\n",
    "        \n",
    "        self._loss = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(self.class_weights))\n",
    "\n",
    "        initializer(self)\n",
    "\n",
    "    def forward(  # type: ignore\n",
    "        self,\n",
    "        premise: TextFieldTensors,\n",
    "        hypothesis: TextFieldTensors,\n",
    "        label: torch.IntTensor = None,\n",
    "        metadata: List[Dict[str, Any]] = None,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "        \"\"\"\n",
    "        # Parameters\n",
    "        premise : `TextFieldTensors`\n",
    "            From a `TextField`\n",
    "        hypothesis : `TextFieldTensors`\n",
    "            From a `TextField`\n",
    "        label : `torch.IntTensor`, optional (default = `None`)\n",
    "            From a `LabelField`\n",
    "        metadata : `List[Dict[str, Any]]`, optional (default = `None`)\n",
    "            Metadata containing the original tokenization of the premise and\n",
    "            hypothesis with 'premise_tokens' and 'hypothesis_tokens' keys respectively.\n",
    "        # Returns\n",
    "        An output dictionary consisting of:\n",
    "        label_logits : `torch.FloatTensor`\n",
    "            A tensor of shape `(batch_size, num_labels)` representing unnormalised log\n",
    "            probabilities of the entailment label.\n",
    "        label_probs : `torch.FloatTensor`\n",
    "            A tensor of shape `(batch_size, num_labels)` representing probabilities of the\n",
    "            entailment label.\n",
    "        loss : `torch.FloatTensor`, optional\n",
    "            A scalar loss to be optimised.\n",
    "        \"\"\"\n",
    "        embedded_premise = self._text_field_embedder(premise)\n",
    "        embedded_hypothesis = self._text_field_embedder(hypothesis)\n",
    "        premise_mask = get_text_field_mask(premise)\n",
    "        hypothesis_mask = get_text_field_mask(hypothesis)\n",
    "\n",
    "        # apply dropout for LSTM\n",
    "        if self.rnn_input_dropout:\n",
    "            embedded_premise = self.rnn_input_dropout(embedded_premise)\n",
    "            embedded_hypothesis = self.rnn_input_dropout(embedded_hypothesis)\n",
    "\n",
    "        # encode premise and hypothesis\n",
    "        encoded_premise = self._encoder(embedded_premise, premise_mask)\n",
    "        encoded_hypothesis = self._encoder(embedded_hypothesis, hypothesis_mask)\n",
    "\n",
    "        # Shape: (batch_size, premise_length, hypothesis_length)\n",
    "        similarity_matrix = self._matrix_attention(encoded_premise, encoded_hypothesis)\n",
    "\n",
    "        # Shape: (batch_size, premise_length, hypothesis_length)\n",
    "        p2h_attention = masked_softmax(similarity_matrix, hypothesis_mask)\n",
    "        # Shape: (batch_size, premise_length, embedding_dim)\n",
    "        attended_hypothesis = weighted_sum(encoded_hypothesis, p2h_attention)\n",
    "\n",
    "        # Shape: (batch_size, hypothesis_length, premise_length)\n",
    "        h2p_attention = masked_softmax(similarity_matrix.transpose(1, 2).contiguous(), premise_mask)\n",
    "        # Shape: (batch_size, hypothesis_length, embedding_dim)\n",
    "        attended_premise = weighted_sum(encoded_premise, h2p_attention)\n",
    "\n",
    "        # the \"enhancement\" layer\n",
    "        premise_enhanced = torch.cat(\n",
    "            [\n",
    "                encoded_premise,\n",
    "                attended_hypothesis,\n",
    "                encoded_premise - attended_hypothesis,\n",
    "                encoded_premise * attended_hypothesis,\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        hypothesis_enhanced = torch.cat(\n",
    "            [\n",
    "                encoded_hypothesis,\n",
    "                attended_premise,\n",
    "                encoded_hypothesis - attended_premise,\n",
    "                encoded_hypothesis * attended_premise,\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        # The projection layer down to the model dimension.  Dropout is not applied before\n",
    "        # projection.\n",
    "        projected_enhanced_premise = self._projection_feedforward(premise_enhanced)\n",
    "        projected_enhanced_hypothesis = self._projection_feedforward(hypothesis_enhanced)\n",
    "\n",
    "        # Run the inference layer\n",
    "        if self.rnn_input_dropout:\n",
    "            projected_enhanced_premise = self.rnn_input_dropout(projected_enhanced_premise)\n",
    "            projected_enhanced_hypothesis = self.rnn_input_dropout(projected_enhanced_hypothesis)\n",
    "        v_ai = self._inference_encoder(projected_enhanced_premise, premise_mask)\n",
    "        v_bi = self._inference_encoder(projected_enhanced_hypothesis, hypothesis_mask)\n",
    "\n",
    "        # The pooling layer -- max and avg pooling.\n",
    "        # (batch_size, model_dim)\n",
    "        v_a_max = masked_max(v_ai, premise_mask.unsqueeze(-1), dim=1)\n",
    "        v_b_max = masked_max(v_bi, hypothesis_mask.unsqueeze(-1), dim=1)\n",
    "\n",
    "        v_a_avg = torch.sum(v_ai * premise_mask.unsqueeze(-1), dim=1) / torch.sum(\n",
    "            premise_mask, 1, keepdim=True\n",
    "        )\n",
    "        v_b_avg = torch.sum(v_bi * hypothesis_mask.unsqueeze(-1), dim=1) / torch.sum(\n",
    "            hypothesis_mask, 1, keepdim=True\n",
    "        )\n",
    "\n",
    "        # Now concat\n",
    "        # (batch_size, model_dim * 2 * 4)\n",
    "        v_all = torch.cat([v_a_avg, v_a_max, v_b_avg, v_b_max], dim=1)\n",
    "\n",
    "        # the final MLP -- apply dropout to input, and MLP applies to output & hidden\n",
    "        if self.dropout:\n",
    "            v_all = self.dropout(v_all)\n",
    "\n",
    "        output_hidden = self._output_feedforward(v_all)\n",
    "        label_logits = self._output_logit(output_hidden)\n",
    "        label_probs = torch.nn.functional.softmax(label_logits, dim=-1)\n",
    "\n",
    "        output_dict = {\"label_logits\": label_logits, \"label_probs\": label_probs}\n",
    "\n",
    "        if label is not None:\n",
    "            loss = self._loss(label_logits, label.long().view(-1))\n",
    "            output_dict[\"loss\"] = loss\n",
    "            \n",
    "            for metric in self.metrics.values():\n",
    "                metric(label_logits, label.long().view(-1))\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        metrics = {\"accuracy\": self.metrics[\"accuracy\"].get_metric(reset=reset)}\n",
    "        \n",
    "        for _class in range(len(self.class_weights)):\n",
    "            metrics.update({\n",
    "                f\"f1_rel{_class}\": self.metrics[f\"f1_rel{_class}\"].get_metric(reset=reset)['f1'],\n",
    "            })\n",
    "        \n",
    "        metrics[\"f1_macro\"] = numpy.mean([metrics[f\"f1_rel{_class}\"] for _class in range(len(self.class_weights))])\n",
    "        return metrics\n",
    "\n",
    "    default_predictor = \"textual_entailment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp models/bimpm_custom_package/model/esim.py ../../../maintenance_rst/models/customization_package/model/esim.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate config files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ELMo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models/label_predictor_esim/config_elmo.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $MODEL_PATH/config_elmo.json\n",
    "\n",
    "local NUM_EPOCHS = 200;\n",
    "local LR = 1e-3;\n",
    "local LSTM_ENCODER_HIDDEN = 25;\n",
    "\n",
    "{\n",
    "  \"dataset_reader\": {\n",
    "    \"type\": \"quora_paraphrase\",\n",
    "    \"tokenizer\": {\n",
    "      \"type\": \"just_spaces\"\n",
    "    },\n",
    "    \"token_indexers\": {\n",
    "      \"token_characters\": {\n",
    "        \"type\": \"characters\",\n",
    "        \"min_padding_length\": 30,\n",
    "      },\n",
    "      \"elmo\": {\n",
    "        \"type\": \"elmo_characters\"\n",
    "     }\n",
    "    }\n",
    "  },\n",
    "  \"train_data_path\": \"label_predictor_esim/nlabel_cf_train.tsv\",\n",
    "  \"validation_data_path\": \"label_predictor_esim/nlabel_cf_dev.tsv\",\n",
    "  \"test_data_path\": \"label_predictor_esim/nlabel_cf_test.tsv\",\n",
    "  \"model\": {\n",
    "    \"type\": \"custom_esim\",\n",
    "    \"dropout\": 0.5,\n",
    "    \"class_weights\": [\n",
    "        0.027483, 0.032003, 0.080478, 0.102642, 0.121394, 0.135027,\n",
    "        0.136856, 0.170897, 0.172355, 0.181655, 0.193858, 0.211297,\n",
    "        0.231651, 0.260982, 0.334437, 0.378277, 0.392996, 0.567416,\n",
    "        0.782946, 0.855932, 0.971154, 1.0],\n",
    "    \"encode_together\": false,\n",
    "    \"text_field_embedder\": {\n",
    "        \"token_embedders\": {\n",
    "            \"elmo\": {\n",
    "                    \"type\": \"elmo_token_embedder\",\n",
    "                    \"options_file\": \"rsv_elmo/options.json\",\n",
    "                    \"weight_file\": \"rsv_elmo/model.hdf5\",\n",
    "                    \"do_layer_norm\": false,\n",
    "                    \"dropout\": 0.1\n",
    "            },\n",
    "            \"token_characters\": {\n",
    "                \"type\": \"character_encoding\",\n",
    "                \"dropout\": 0.1,\n",
    "                \"embedding\": {\n",
    "                    \"embedding_dim\": 20,\n",
    "                    \"padding_index\": 0,\n",
    "                    \"vocab_namespace\": \"token_characters\"\n",
    "                },\n",
    "                \"encoder\": {\n",
    "                    \"type\": \"lstm\",\n",
    "                    \"input_size\": $.model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim,\n",
    "                    \"hidden_size\": LSTM_ENCODER_HIDDEN,\n",
    "                    \"num_layers\": 1,\n",
    "                    \"bidirectional\": true,\n",
    "                    \"dropout\": 0.4\n",
    "                },\n",
    "            },\n",
    "      }\n",
    "    },\n",
    "    \"encoder\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"input_size\": 1024+LSTM_ENCODER_HIDDEN+LSTM_ENCODER_HIDDEN,\n",
    "      \"hidden_size\": 300,\n",
    "      \"num_layers\": 1,\n",
    "      \"bidirectional\": true\n",
    "    },\n",
    "    \"matrix_attention\": {\"type\": \"dot_product\"},\n",
    "    \"projection_feedforward\": {\n",
    "      \"input_dim\": 2400,\n",
    "      \"hidden_dims\": 300,\n",
    "      \"num_layers\": 1,\n",
    "      \"activations\": \"relu\"\n",
    "    },\n",
    "    \"inference_encoder\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"input_size\": 300,\n",
    "      \"hidden_size\": 300,\n",
    "      \"num_layers\": 1,\n",
    "      \"bidirectional\": true\n",
    "    },\n",
    "    \"output_feedforward\": {\n",
    "      \"input_dim\": 2400,\n",
    "      \"num_layers\": 1,\n",
    "      \"hidden_dims\": 300,\n",
    "      \"activations\": \"relu\",\n",
    "      \"dropout\": 0.5\n",
    "    },\n",
    "    \"output_logit\": {\n",
    "      \"input_dim\": 300,\n",
    "      \"num_layers\": 1,\n",
    "      \"hidden_dims\": 22,\n",
    "      \"activations\": \"linear\"\n",
    "    },\n",
    "    \"initializer\": {\n",
    "      \"regexes\": [\n",
    "        [\".*linear_layers.*weight\", {\"type\": \"xavier_normal\"}],\n",
    "        [\".*linear_layers.*bias\", {\"type\": \"constant\", \"val\": 0}],\n",
    "        [\".*weight_ih.*\", {\"type\": \"xavier_normal\"}],\n",
    "        [\".*weight_hh.*\", {\"type\": \"orthogonal\"}],\n",
    "        [\".*bias.*\", {\"type\": \"constant\", \"val\": 0}],\n",
    "        [\".*matcher.*match_weights.*\", {\"type\": \"kaiming_normal\"}]\n",
    "      ]\n",
    "    }\n",
    "   },\n",
    "  \"data_loader\": {\n",
    "    \"batch_sampler\": {\n",
    "        \"type\": \"bucket\",\n",
    "        \"batch_size\": 20,\n",
    "        \"padding_noise\": 0.0,\n",
    "        \"sorting_keys\": [\"premise\"],\n",
    "    },\n",
    "  },\n",
    "  \"trainer\": {\n",
    "    \"num_epochs\": NUM_EPOCHS,\n",
    "    \"cuda_device\": 1,\n",
    "    \"grad_clipping\": 5.0,\n",
    "    \"validation_metric\": \"+f1_macro\",\n",
    "    \"shuffle\": true,\n",
    "    \"optimizer\": {\n",
    "      \"type\": \"adam\",\n",
    "      \"lr\": LR\n",
    "    },\n",
    "    \"learning_rate_scheduler\": {\n",
    "      \"type\": \"reduce_on_plateau\",\n",
    "      \"factor\": 0.5,\n",
    "      \"mode\": \"max\",\n",
    "      \"patience\": 0\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -r $MODEL_PATH ../../../maintenance_rst/models/label_predictor_esim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -r $MODEL_PATH/config_elmo.json ../../../maintenance_rst/models/label_predictor_esim/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Scripts for training/prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1. Directly from the config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models/train_label_predictor_esim.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile models/train_label_predictor_esim.sh\n",
    "# usage:\n",
    "# $ cd models \n",
    "# $ sh train_label_predictor.sh {bert|elmo} result_30\n",
    "\n",
    "export METHOD=${1}\n",
    "export RESULT_DIR=${2}\n",
    "export DEV_FILE_PATH=\"nlabel_cf_dev.tsv\"\n",
    "export TEST_FILE_PATH=\"nlabel_cf_test.tsv\"\n",
    "\n",
    "rm -r label_predictor_esim/${RESULT_DIR}/\n",
    "allennlp train -s label_predictor_esim/${RESULT_DIR}/ label_predictor_esim/config_${METHOD}.json \\\n",
    "    --include-package bimpm_custom_package\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_esim/${RESULT_DIR}/predictions_dev.json label_predictor_esim/${RESULT_DIR}/model.tar.gz label_predictor_esim/${DEV_FILE_PATH} \\\n",
    "    --include-package bimpm_custom_package \\\n",
    "    --predictor textual-entailment\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_esim/${RESULT_DIR}/predictions_test.json label_predictor_esim/${RESULT_DIR}/model.tar.gz label_predictor_esim/${TEST_FILE_PATH} \\\n",
    "    --include-package bimpm_custom_package \\\n",
    "    --predictor textual-entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp models/train_label_predictor_esim.sh ../../../maintenance_rst/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on dev&test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models/eval_label_predictor_esim.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile models/eval_label_predictor_esim.sh\n",
    "# usage:\n",
    "# $ cd models \n",
    "# $ sh train_label_predictor.sh {bert|elmo} result_30\n",
    "\n",
    "export METHOD=${1}\n",
    "export RESULT_DIR=${2}\n",
    "export DEV_FILE_PATH=\"nlabel_cf_dev.tsv\"\n",
    "export TEST_FILE_PATH=\"nlabel_cf_test.tsv\"\n",
    "\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_esim/${RESULT_DIR}/predictions_dev.json label_predictor_esim/${RESULT_DIR}/model.tar.gz label_predictor_esim/${DEV_FILE_PATH} \\\n",
    "    --include-package bimpm_custom_package \\\n",
    "    --predictor textual-entailment\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_esim/${RESULT_DIR}/predictions_test.json label_predictor_esim/${RESULT_DIR}/model.tar.gz label_predictor_esim/${TEST_FILE_PATH} \\\n",
    "    --include-package bimpm_custom_package \\\n",
    "    --predictor textual-entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp models/eval_label_predictor_esim.sh ../../../maintenance_rst/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(optional) predict on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile models/eval_label_predictor_train.sh\n",
    "# usage:\n",
    "# $ cd models \n",
    "# $ sh eval_label_predictor_train.sh {bert|elmo} result_30\n",
    "\n",
    "export METHOD=${1}\n",
    "export RESULT_DIR=${2}\n",
    "export TEST_FILE_PATH=\"nlabel_cf_train.tsv\"\n",
    "\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_bimpm/${RESULT_DIR}/predictions_train.json label_predictor_bimpm/${RESULT_DIR}/model.tar.gz label_predictor_bimpm/${TEST_FILE_PATH} \\\n",
    "    --include-package customization_package \\\n",
    "    --predictor textual-entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2. Using wandb for parameters adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile ../../../maintenance_rst/models/wandb_label_predictor_esim.yaml\n",
    "\n",
    "name: label_predictor_esim\n",
    "program: wandb_allennlp # this is a wrapper console script around allennlp commands. It is part of wandb-allennlp\n",
    "method: bayes\n",
    "## Do not for get to use the command keyword to specify the following command structure\n",
    "command:\n",
    "  - ${program} #omit the interpreter as we use allennlp train command directly\n",
    "  - \"--subcommand=train\"\n",
    "  - \"--include-package=customization_package\" # add all packages containing your registered classes here\n",
    "  - \"--config_file=label_predictor_esim/config_elmo.json\"\n",
    "  - ${args}\n",
    "metric:\n",
    "    name: best_f1_macro\n",
    "    goal: maximize\n",
    "parameters:\n",
    "    model.encode_together:\n",
    "        values: [\"true\", ]    \n",
    "    iterator.batch_size:\n",
    "        values: [8,]\n",
    "    trainer.optimizer.lr:\n",
    "        values: [0.001,]\n",
    "    model.dropout:\n",
    "        values: [0.5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``wandb sweep wandb_label_predictor_esim.yaml``\n",
    "\n",
    "(returns %sweepname1)\n",
    "\n",
    "``wandb sweep wandb_label_predictor2.yaml``\n",
    "\n",
    "(returns %sweepname2)\n",
    "\n",
    "``wandb agent --count 1 %sweepname1 && wandb agent --count 1 %sweepname2``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the best model in label_predictor_bimpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls -laht models/wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -r models/wandb/run-20201218_123424-kcphaqhi/training_dumps models/label_predictor_esim/esim_elmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Or** load from wandb by %sweepname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "api = wandb.Api()\n",
    "run = api.run(\"tchewik/tmp/7hum4oom\")\n",
    "for file in run.files():\n",
    "    file.download(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -r training_dumps models/label_predictor_bimpm/toasty-sweep-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run evaluation from shell\n",
    "\n",
    "``sh eval_label_predictor_esim.sh {elmo|elmo_fasttext} toasty-sweep-1``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predictions(path):\n",
    "    result = []\n",
    "    vocab = []\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            line = json.loads(line)\n",
    "            if line.get(\"label\"):\n",
    "                result.append(line.get(\"label\"))\n",
    "            elif line.get(\"label_probs\"):\n",
    "                if not vocab:\n",
    "                    vocab = open(path[:path.rfind('/')] + '/vocabulary/labels.txt', 'r').readlines()\n",
    "                    vocab = [label.strip() for label in vocab]\n",
    "                \n",
    "                result.append(vocab[np.argmax(line.get(\"label_probs\"))])\n",
    "            \n",
    "    print('length of result:', len(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = 'esim_elmo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir models/label_predictor_esim/$RESULT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -r ../../../maintenance_rst/models/label_predictor_esim/$RESULT_DIR/*.json models/label_predictor_esim/$RESULT_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of result: 3596\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "true = pd.read_csv(DEV_FILE_PATH, sep='\\t', header=None)[0].values.tolist()\n",
    "pred = load_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "              attribution_NS     0.8488    0.8902    0.8690        82\n",
      "              attribution_SN     0.8830    0.8343    0.8580       181\n",
      "               background_NS     0.2113    0.1685    0.1875        89\n",
      "             cause-effect_NS     0.6094    0.5000    0.5493       156\n",
      "             cause-effect_SN     0.4451    0.4425    0.4438       174\n",
      "               comparison_NN     0.1236    0.2115    0.1560        52\n",
      "               concession_NS     0.9000    0.5625    0.6923        32\n",
      "                condition_NS     0.6111    0.6197    0.6154        71\n",
      "                condition_SN     0.7008    0.8241    0.7574       108\n",
      "                 contrast_NN     0.7387    0.6119    0.6694       268\n",
      "              elaboration_NS     0.3530    0.5575    0.4323       644\n",
      "                 evidence_NS     0.1235    0.1887    0.1493        53\n",
      "interpretation-evaluation_NS     0.3008    0.3540    0.3252       226\n",
      "interpretation-evaluation_SN     0.5000    0.3214    0.3913        28\n",
      "                    joint_NN     0.7661    0.3984    0.5242       748\n",
      "              preparation_SN     0.4000    0.2581    0.3137       186\n",
      "                  purpose_NS     0.8588    0.7849    0.8202        93\n",
      "                  purpose_SN     0.6154    0.8889    0.7273        18\n",
      "              restatement_NN     0.3333    0.3571    0.3448        14\n",
      "                same-unit_NN     0.6881    0.5906    0.6356       127\n",
      "                 sequence_NN     0.4561    0.5450    0.4966       200\n",
      "             solutionhood_SN     0.3889    0.6087    0.4746        46\n",
      "\n",
      "                    accuracy                         0.5089      3596\n",
      "                   macro avg     0.5389    0.5236    0.5197      3596\n",
      "                weighted avg     0.5641    0.5089    0.5168      3596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(true[:len(pred)], pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([86.9047619 , 85.79545455, 18.75      , 54.92957746, 44.38040346,\n",
       "       15.60283688, 69.23076923, 61.53846154, 75.74468085, 66.93877551,\n",
       "       43.2269717 , 14.92537313, 32.5203252 , 39.13043478, 52.41864556,\n",
       "       31.37254902, 82.02247191, 72.72727273, 34.48275862, 63.55932203,\n",
       "       49.65831435, 47.45762712, 51.96899034, 51.68428547])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics = classification_report(true[:len(pred)], pred, digits=4, output_dict=True)\n",
    "test_f1 = np.array(\n",
    "    [test_metrics[label].get('f1-score') for label in test_metrics if type(test_metrics[label]) == dict]) * 100\n",
    "\n",
    "test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3596"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 51.97\n",
      "pr: 53.89\n",
      "re: 52.36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(true[:len(pred)], pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_confusion_matrix import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = list(set(true))\n",
    "labels.sort()\n",
    "plot_confusion_matrix(confusion_matrix(true[:len(pred)], pred, labels), target_names=labels, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_classes = [\n",
    "    'attribution_NS',\n",
    "    'attribution_SN',\n",
    "    'purpose_NS',\n",
    "    'purpose_SN',\n",
    "    'condition_SN',\n",
    "    'contrast_NN',\n",
    "    'condition_NS',\n",
    "    'joint_NN',\n",
    "    'concession_NS',\n",
    "    'same-unit_NN',\n",
    "    'elaboration_NS',\n",
    "    'cause-effect_NS',\n",
    "]\n",
    "\n",
    "class_mapper = {weird_class: 'other' + weird_class[-3:] for weird_class in labels if not weird_class in top_classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "true = [class_mapper.get(value) if class_mapper.get(value) else value for value in true]\n",
    "pred = [class_mapper.get(value) if class_mapper.get(value) else value for value in pred]\n",
    "\n",
    "pred_mapper = {\n",
    "    'other_NN': 'joint_NN',\n",
    "    'other_NS': 'joint_NN',\n",
    "    'other_SN': 'joint_NN'\n",
    "}\n",
    "pred = [pred_mapper.get(value) if pred_mapper.get(value) else value for value in pred]\n",
    "\n",
    "_to_stay = (np.array(true) != 'other_NN') & (np.array(true) != 'other_SN') & (np.array(true) != 'other_NS')\n",
    "\n",
    "_true = np.array(true)[_to_stay]\n",
    "_pred = np.array(pred)[_to_stay[:len(pred)]]\n",
    "labels = list(set(_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(true[:len(pred)], pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(_true[:len(_pred)], _pred), target_names=labels, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for rel in np.unique(_true):\n",
    "    print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On train set (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "true = pd.read_csv('models/label_predictor_bimpm/nlabel_cf_train.tsv', sep='\\t', header=None)[0].values.tolist()\n",
    "pred = load_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_train.json')\n",
    "\n",
    "print(classification_report(true[:len(pred)], pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = 'models/label_predictor_lstm/nlabel_cf_train.tsv'\n",
    "true_train = pd.read_csv(file, sep='\\t', header=None)\n",
    "true_train['predicted_relation'] = pred\n",
    "\n",
    "print(true_train[true_train.relation != true_train.predicted_relation].shape)\n",
    "\n",
    "true_train[true_train.relation != true_train.predicted_relation].to_csv('mispredicted_relations.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of result: 2518\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-78261ab06c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{MODEL_PATH}/{RESULT_DIR}/predictions_test.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "true = pd.read_csv(TEST_FILE_PATH, sep='\\t', header=None)[0].values.tolist()\n",
    "pred = load_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_test.json')\n",
    "\n",
    "print(classification_report(true[:len(pred)], pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = classification_report(true[:len(pred)], pred, digits=4, output_dict=True)\n",
    "test_f1 = np.array(\n",
    "    [test_metrics[label].get('f1-score') for label in test_metrics if type(test_metrics[label]) == dict]) * 100\n",
    "\n",
    "test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(true[:len(pred)], pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = [class_mapper.get(value) if class_mapper.get(value) else value for value in true]\n",
    "pred = [class_mapper.get(value) if class_mapper.get(value) else value for value in pred]\n",
    "pred = [pred_mapper.get(value) if pred_mapper.get(value) else value for value in pred]\n",
    "\n",
    "_to_stay = (np.array(true) != 'other_NN') & (np.array(true) != 'other_SN') & (np.array(true) != 'other_NS')\n",
    "\n",
    "_true = np.array(true)[_to_stay]\n",
    "_pred = np.array(pred)[_to_stay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(_true[:len(_pred)], _pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(_true[:len(_pred)], _pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble: (Logreg+Catboost) + ESIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls models/label_predictor_esim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model_vocab = open(MODEL_PATH + '/' + RESULT_DIR + '/vocabulary/labels.txt', 'r').readlines()\n",
    "model_vocab = [label.strip() for label in model_vocab]\n",
    "\n",
    "catboost_vocab = [\n",
    "   'attribution_NS', 'attribution_SN', 'background_NS',\n",
    "   'cause-effect_NS', 'cause-effect_SN', 'comparison_NN',\n",
    "   'concession_NS', 'condition_NS', 'condition_SN', 'contrast_NN',\n",
    "   'elaboration_NS', 'evidence_NS', 'interpretation-evaluation_NS',\n",
    "   'interpretation-evaluation_SN', 'joint_NN', 'preparation_SN',\n",
    "   'purpose_NS', 'purpose_SN', 'restatement_NN', 'same-unit_NN',\n",
    "   'sequence_NN', 'solutionhood_SN']\n",
    "\n",
    "def load_neural_predictions(path):\n",
    "    result = []\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            line = json.loads(line)\n",
    "            if line.get('probs'):\n",
    "                probs = line.get('probs')\n",
    "            elif line.get('label_probs'):\n",
    "                probs = line.get('label_probs')\n",
    "            probs = {model_vocab[i]: probs[i] for i in range(len(model_vocab))}\n",
    "            result.append(probs)\n",
    "            \n",
    "    return result\n",
    "\n",
    "def load_scikit_predictions(model, X):\n",
    "    result = []\n",
    "    predictions = model.predict_proba(X)\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        probs = {catboost_vocab[j]: prediction[j] for j in range(len(catboost_vocab))}\n",
    "        result.append(probs)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def vote_predictions(predictions, soft=True, weights=[1., 1.]):\n",
    "    for i in range(1, len(predictions)):\n",
    "        assert len(predictions[i-1]) == len(predictions[i])\n",
    "        \n",
    "    if weights == [1., 1.]:\n",
    "        weights = [1.,] * len(predictions)\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i in range(len(predictions[0])):\n",
    "        sample_result = {}\n",
    "        for key in predictions[0][i].keys():\n",
    "            if soft:\n",
    "                sample_result[key] = 0\n",
    "                for j, prediction in enumerate(predictions):\n",
    "                    sample_result[key] += prediction[i][key] * weights[j]\n",
    "            else:\n",
    "                sample_result[key] = max([pred[i][key] * weights[j] for j, pred in enumerate(predictions)])\n",
    "\n",
    "        \n",
    "        result.append(sample_result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def probs_to_classes(pred):\n",
    "    result = []\n",
    "    \n",
    "    for sample in pred:\n",
    "        best_class = ''\n",
    "        best_prob = 0.\n",
    "        for key in sample.keys():\n",
    "            if sample[key] > best_prob:\n",
    "                best_prob = sample[key]\n",
    "                best_class = key\n",
    "        \n",
    "        result.append(best_class)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-0.24.4-cp37-none-manylinux1_x86_64.whl (65.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 65.7 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from catboost) (1.14.0)\n",
      "Requirement already satisfied: plotly in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from catboost) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from catboost) (1.18.1)\n",
      "Requirement already satisfied: scipy in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from catboost) (0.25.3)\n",
      "Requirement already satisfied: graphviz in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from catboost) (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from catboost) (3.1.2)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pandas>=0.24.0->catboost) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from matplotlib->catboost) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from matplotlib->catboost) (2.4.6)\n",
      "Requirement already satisfied: setuptools in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (45.1.0)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-0.24.4\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/opt/.pyenv/versions/3.7.4/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.22.2.post1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator VotingClassifier from version 0.22.2.post1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.22.2.post1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "fs_catboost_plus_logreg = pickle.load(open('models/relation_predictor_baseline/model.pkl', 'rb'))\n",
    "lab_encoder = pickle.load(open('models/relation_predictor_baseline/label_encoder.pkl', 'rb'))\n",
    "scaler = pickle.load(open('models/relation_predictor_baseline/scaler.pkl', 'rb'))\n",
    "drop_columns = pickle.load(open('models/relation_predictor_baseline/drop_columns.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted f1:  0.5413872373769657\n",
      "macro f1:  0.5354738926873194\n",
      "accuracy:  0.5389321468298109\n",
      "\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "              attribution_NS     0.8409    0.9024    0.8706        82\n",
      "              attribution_SN     0.8424    0.8564    0.8493       181\n",
      "               background_NS     0.2167    0.1461    0.1745        89\n",
      "             cause-effect_NS     0.6015    0.5128    0.5536       156\n",
      "             cause-effect_SN     0.5096    0.4598    0.4834       174\n",
      "               comparison_NN     0.1449    0.1923    0.1653        52\n",
      "               concession_NS     0.9000    0.5625    0.6923        32\n",
      "                condition_NS     0.6438    0.6620    0.6528        71\n",
      "                condition_SN     0.6716    0.8333    0.7438       108\n",
      "                 contrast_NN     0.7229    0.6231    0.6693       268\n",
      "              elaboration_NS     0.3932    0.5776    0.4679       644\n",
      "                 evidence_NS     0.1698    0.1698    0.1698        53\n",
      "interpretation-evaluation_NS     0.3281    0.3717    0.3485       226\n",
      "interpretation-evaluation_SN     0.5294    0.3214    0.4000        28\n",
      "                    joint_NN     0.6974    0.5053    0.5860       748\n",
      "              preparation_SN     0.4153    0.2634    0.3224       186\n",
      "                  purpose_NS     0.8506    0.7957    0.8222        93\n",
      "                  purpose_SN     0.6667    0.8889    0.7619        18\n",
      "              restatement_NN     0.4167    0.3571    0.3846        14\n",
      "                same-unit_NN     0.7064    0.6063    0.6525       127\n",
      "                 sequence_NN     0.4585    0.5250    0.4895       200\n",
      "             solutionhood_SN     0.4815    0.5652    0.5200        46\n",
      "\n",
      "                    accuracy                         0.5389      3596\n",
      "                   macro avg     0.5549    0.5317    0.5355      3596\n",
      "                weighted avg     0.5623    0.5389    0.5414      3596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "TARGET = 'relation'\n",
    "\n",
    "y_dev, X_dev = dev_samples['relation'].to_frame(), dev_samples.drop('relation', axis=1).drop(\n",
    "    columns=drop_columns + ['category_id', 'index'])\n",
    "\n",
    "X_scaled_np = scaler.transform(X_dev)\n",
    "X_dev = pd.DataFrame(X_scaled_np, index=X_dev.index)\n",
    "\n",
    "catboost_predictions = load_scikit_predictions(fs_catboost_plus_logreg, X_dev)\n",
    "neural_predictions = load_neural_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_dev.json')\n",
    "\n",
    "tmp = vote_predictions([neural_predictions, catboost_predictions], soft=True, weights=[1., 1.])\n",
    "ensemble_pred = probs_to_classes(tmp)\n",
    "\n",
    "print('weighted f1: ', metrics.f1_score(y_dev.values, ensemble_pred, average='weighted'))\n",
    "print('macro f1: ', metrics.f1_score(y_dev.values, ensemble_pred, average='macro'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_dev.values, ensemble_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_dev, ensemble_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_samples = test_samples[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = _test_samples[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = test_samples.filename.str.contains('news')\n",
    "test_samples = test_samples[test_samples['filename'].str.contains('news')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2518,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2518, 2064)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_predictions(predictions, mask):\n",
    "    result = []\n",
    "    mask = mask.values\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        if mask[i]:\n",
    "            result.append(prediction)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted f1:  0.5610757855765772\n",
      "macro f1:  0.510472638133765\n",
      "accuracy:  0.5647339158061954\n",
      "\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "              attribution_NS     0.8800    1.0000    0.9362        44\n",
      "              attribution_SN     0.8182    0.9435    0.8764       124\n",
      "               background_NS     0.0370    0.0385    0.0377        26\n",
      "             cause-effect_NS     0.4949    0.6364    0.5568        77\n",
      "             cause-effect_SN     0.5464    0.4309    0.4818       123\n",
      "               comparison_NN     0.1250    0.2000    0.1538        35\n",
      "               concession_NS     0.4444    0.4000    0.4211        10\n",
      "                condition_NS     0.5977    0.7647    0.6710        68\n",
      "                condition_SN     0.6869    0.8500    0.7598        80\n",
      "                 contrast_NN     0.6510    0.6188    0.6345       202\n",
      "              elaboration_NS     0.5337    0.6323    0.5789       563\n",
      "                 evidence_NS     0.0400    0.0435    0.0417        23\n",
      "interpretation-evaluation_NS     0.3355    0.3893    0.3604       131\n",
      "interpretation-evaluation_SN     0.5455    0.3529    0.4286        17\n",
      "                    joint_NN     0.6374    0.5203    0.5729       517\n",
      "              preparation_SN     0.4028    0.2613    0.3169       111\n",
      "                  purpose_NS     0.8025    0.8228    0.8125        79\n",
      "                  purpose_SN     0.6923    0.9000    0.7826        20\n",
      "              restatement_NN     0.4706    0.4211    0.4444        19\n",
      "                same-unit_NN     0.8070    0.5476    0.6525        84\n",
      "                 sequence_NN     0.4750    0.3016    0.3689       126\n",
      "             solutionhood_SN     0.3061    0.3846    0.3409        39\n",
      "\n",
      "                    accuracy                         0.5647      2518\n",
      "                   macro avg     0.5150    0.5209    0.5105      2518\n",
      "                weighted avg     0.5707    0.5647    0.5611      2518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TARGET = 'relation'\n",
    "\n",
    "y_test, X_test = test_samples[TARGET].to_frame(), test_samples.drop(TARGET, axis=1).drop(\n",
    "    columns=drop_columns + ['category_id', 'index'])\n",
    "\n",
    "X_scaled_np = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_scaled_np, index=X_test.index)\n",
    "\n",
    "catboost_predictions = load_scikit_predictions(fs_catboost_plus_logreg, X_test)\n",
    "neural_predictions = load_neural_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_test.json')\n",
    "# neural_predictions = mask_predictions(neural_predictions, mask)\n",
    "\n",
    "tmp = vote_predictions([neural_predictions, catboost_predictions], soft=True, weights=[1., 2.])\n",
    "\n",
    "ensemble_pred = probs_to_classes(tmp)\n",
    "\n",
    "print('weighted f1: ', metrics.f1_score(y_test.values, ensemble_pred, average='weighted'))\n",
    "print('macro f1: ', metrics.f1_score(y_test.values, ensemble_pred, average='macro'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_test.values, ensemble_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, ensemble_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = test_samples[['snippet_x', 'snippet_y', 'category_id', 'order', 'filename']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "output['true'] = output['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "output['predicted'] = ensemble_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snippet_x</th>\n",
       "      <th>snippet_y</th>\n",
       "      <th>category_id</th>\n",
       "      <th>order</th>\n",
       "      <th>filename</th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Недостатком этого варианта является то ,</td>\n",
       "      <td>что настроиться на занятия сложнее , чем в орг...</td>\n",
       "      <td>interpretation-evaluation</td>\n",
       "      <td>SN</td>\n",
       "      <td>blogs_31</td>\n",
       "      <td>interpretation-evaluation</td>\n",
       "      <td>attribution_SN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>По словам аналитика ,</td>\n",
       "      <td>ОДКБ ― сравнительно молодая организация , кото...</td>\n",
       "      <td>attribution</td>\n",
       "      <td>SN</td>\n",
       "      <td>news2_34</td>\n",
       "      <td>attribution</td>\n",
       "      <td>attribution_SN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>при попытке совместить</td>\n",
       "      <td>дают какой - то треш</td>\n",
       "      <td>condition</td>\n",
       "      <td>SN</td>\n",
       "      <td>blogs_72</td>\n",
       "      <td>condition</td>\n",
       "      <td>condition_SN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>У нас есть несколько продуктов и менеджеров с ...</td>\n",
       "      <td>и там можно применить весь тестерский матан</td>\n",
       "      <td>joint</td>\n",
       "      <td>NN</td>\n",
       "      <td>blogs_39</td>\n",
       "      <td>joint</td>\n",
       "      <td>joint_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>У Министерства практических пророков полно ,</td>\n",
       "      <td>а он почему - то их ищет в беспомощном , консе...</td>\n",
       "      <td>contrast</td>\n",
       "      <td>NN</td>\n",
       "      <td>news2_16</td>\n",
       "      <td>contrast</td>\n",
       "      <td>contrast_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>Пусть ЦБ оставит экспортеров в покое , избавит...</td>\n",
       "      <td>Но что же будет с резервами Центробанка ? А ни...</td>\n",
       "      <td>elaboration</td>\n",
       "      <td>NS</td>\n",
       "      <td>news1_47</td>\n",
       "      <td>elaboration</td>\n",
       "      <td>contrast_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>Идея создания единых мировых критериев для оце...</td>\n",
       "      <td>Однако поиск единых глобальных стандартов упра...</td>\n",
       "      <td>contrast</td>\n",
       "      <td>NN</td>\n",
       "      <td>news1_25</td>\n",
       "      <td>contrast</td>\n",
       "      <td>contrast_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>И ломка у него должна проходить в камере ,</td>\n",
       "      <td>когда он прикован наручниками к</td>\n",
       "      <td>condition</td>\n",
       "      <td>NS</td>\n",
       "      <td>blogs_52</td>\n",
       "      <td>condition</td>\n",
       "      <td>condition_NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>Национальные блюда схожи с бурятскими . Буряты...</td>\n",
       "      <td>В 20 - 30 - е годы 20 века было даже националь...</td>\n",
       "      <td>background</td>\n",
       "      <td>NS</td>\n",
       "      <td>blogs_99</td>\n",
       "      <td>background</td>\n",
       "      <td>elaboration_NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>Люди с плохими границами действуют как слепые ...</td>\n",
       "      <td>все время проецируют на других свои желания</td>\n",
       "      <td>joint</td>\n",
       "      <td>NN</td>\n",
       "      <td>blogs_72</td>\n",
       "      <td>joint</td>\n",
       "      <td>cause-effect_SN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2518 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              snippet_x  \\\n",
       "0              Недостатком этого варианта является то ,   \n",
       "1                                 По словам аналитика ,   \n",
       "2                                при попытке совместить   \n",
       "3     У нас есть несколько продуктов и менеджеров с ...   \n",
       "4          У Министерства практических пророков полно ,   \n",
       "...                                                 ...   \n",
       "2513  Пусть ЦБ оставит экспортеров в покое , избавит...   \n",
       "2514  Идея создания единых мировых критериев для оце...   \n",
       "2515         И ломка у него должна проходить в камере ,   \n",
       "2516  Национальные блюда схожи с бурятскими . Буряты...   \n",
       "2517  Люди с плохими границами действуют как слепые ...   \n",
       "\n",
       "                                              snippet_y  \\\n",
       "0     что настроиться на занятия сложнее , чем в орг...   \n",
       "1     ОДКБ ― сравнительно молодая организация , кото...   \n",
       "2                                  дают какой - то треш   \n",
       "3           и там можно применить весь тестерский матан   \n",
       "4     а он почему - то их ищет в беспомощном , консе...   \n",
       "...                                                 ...   \n",
       "2513  Но что же будет с резервами Центробанка ? А ни...   \n",
       "2514  Однако поиск единых глобальных стандартов упра...   \n",
       "2515                    когда он прикован наручниками к   \n",
       "2516  В 20 - 30 - е годы 20 века было даже националь...   \n",
       "2517        все время проецируют на других свои желания   \n",
       "\n",
       "                    category_id order  filename                       true  \\\n",
       "0     interpretation-evaluation    SN  blogs_31  interpretation-evaluation   \n",
       "1                   attribution    SN  news2_34                attribution   \n",
       "2                     condition    SN  blogs_72                  condition   \n",
       "3                         joint    NN  blogs_39                      joint   \n",
       "4                      contrast    NN  news2_16                   contrast   \n",
       "...                         ...   ...       ...                        ...   \n",
       "2513                elaboration    NS  news1_47                elaboration   \n",
       "2514                   contrast    NN  news1_25                   contrast   \n",
       "2515                  condition    NS  blogs_52                  condition   \n",
       "2516                 background    NS  blogs_99                 background   \n",
       "2517                      joint    NN  blogs_72                      joint   \n",
       "\n",
       "            predicted  \n",
       "0      attribution_SN  \n",
       "1      attribution_SN  \n",
       "2        condition_SN  \n",
       "3            joint_NN  \n",
       "4         contrast_NN  \n",
       "...               ...  \n",
       "2513      contrast_NN  \n",
       "2514      contrast_NN  \n",
       "2515     condition_NS  \n",
       "2516   elaboration_NS  \n",
       "2517  cause-effect_SN  \n",
       "\n",
       "[2518 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = output[output.true != output.predicted.map(lambda row: row.split('_')[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1095, 7)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snippet_x</th>\n",
       "      <th>snippet_y</th>\n",
       "      <th>order</th>\n",
       "      <th>filename</th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Недостатком этого варианта является то ,</td>\n",
       "      <td>что настроиться на занятия сложнее , чем в орг...</td>\n",
       "      <td>SN</td>\n",
       "      <td>blogs_31</td>\n",
       "      <td>interpretation-evaluation</td>\n",
       "      <td>attribution_SN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Хотя правительство наотрез отказывается занима...</td>\n",
       "      <td>трудно сказать , как пойдут дела в будущем</td>\n",
       "      <td>NN</td>\n",
       "      <td>news1_47</td>\n",
       "      <td>contrast</td>\n",
       "      <td>condition_SN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Все начинается с отделения границ .</td>\n",
       "      <td>Личность с этого начинается</td>\n",
       "      <td>NS</td>\n",
       "      <td>blogs_72</td>\n",
       "      <td>elaboration</td>\n",
       "      <td>joint_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>В русской школе « Ведение в историю » начинает...</td>\n",
       "      <td>В 6 - м - История России с древнейших времен и...</td>\n",
       "      <td>NN</td>\n",
       "      <td>news2_16</td>\n",
       "      <td>sequence</td>\n",
       "      <td>elaboration_NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Но меня не проведешь -</td>\n",
       "      <td>я и буузы нашла с овощами , и цуйван с морепро...</td>\n",
       "      <td>NS</td>\n",
       "      <td>blogs_99</td>\n",
       "      <td>cause-effect</td>\n",
       "      <td>joint_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>Пересела на зеленую ветку , там всегда толпа ,...</td>\n",
       "      <td>читаю книжку на телефоне</td>\n",
       "      <td>SN</td>\n",
       "      <td>blogs_21</td>\n",
       "      <td>cause-effect</td>\n",
       "      <td>sequence_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>И я продолжу делать все , что в моих силах для...</td>\n",
       "      <td>в течение своего нового пятилетнего срока в ев...</td>\n",
       "      <td>NN</td>\n",
       "      <td>news1_23</td>\n",
       "      <td>same-unit</td>\n",
       "      <td>condition_NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>Пусть ЦБ оставит экспортеров в покое , избавит...</td>\n",
       "      <td>Но что же будет с резервами Центробанка ? А ни...</td>\n",
       "      <td>NS</td>\n",
       "      <td>news1_47</td>\n",
       "      <td>elaboration</td>\n",
       "      <td>contrast_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>Национальные блюда схожи с бурятскими . Буряты...</td>\n",
       "      <td>В 20 - 30 - е годы 20 века было даже националь...</td>\n",
       "      <td>NS</td>\n",
       "      <td>blogs_99</td>\n",
       "      <td>background</td>\n",
       "      <td>elaboration_NS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>Люди с плохими границами действуют как слепые ...</td>\n",
       "      <td>все время проецируют на других свои желания</td>\n",
       "      <td>NN</td>\n",
       "      <td>blogs_72</td>\n",
       "      <td>joint</td>\n",
       "      <td>cause-effect_SN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1095 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              snippet_x  \\\n",
       "0              Недостатком этого варианта является то ,   \n",
       "6     Хотя правительство наотрез отказывается занима...   \n",
       "8                   Все начинается с отделения границ .   \n",
       "9     В русской школе « Ведение в историю » начинает...   \n",
       "10                               Но меня не проведешь -   \n",
       "...                                                 ...   \n",
       "2507  Пересела на зеленую ветку , там всегда толпа ,...   \n",
       "2510  И я продолжу делать все , что в моих силах для...   \n",
       "2513  Пусть ЦБ оставит экспортеров в покое , избавит...   \n",
       "2516  Национальные блюда схожи с бурятскими . Буряты...   \n",
       "2517  Люди с плохими границами действуют как слепые ...   \n",
       "\n",
       "                                              snippet_y order  filename  \\\n",
       "0     что настроиться на занятия сложнее , чем в орг...    SN  blogs_31   \n",
       "6            трудно сказать , как пойдут дела в будущем    NN  news1_47   \n",
       "8                           Личность с этого начинается    NS  blogs_72   \n",
       "9     В 6 - м - История России с древнейших времен и...    NN  news2_16   \n",
       "10    я и буузы нашла с овощами , и цуйван с морепро...    NS  blogs_99   \n",
       "...                                                 ...   ...       ...   \n",
       "2507                           читаю книжку на телефоне    SN  blogs_21   \n",
       "2510  в течение своего нового пятилетнего срока в ев...    NN  news1_23   \n",
       "2513  Но что же будет с резервами Центробанка ? А ни...    NS  news1_47   \n",
       "2516  В 20 - 30 - е годы 20 века было даже националь...    NS  blogs_99   \n",
       "2517        все время проецируют на других свои желания    NN  blogs_72   \n",
       "\n",
       "                           true        predicted  \n",
       "0     interpretation-evaluation   attribution_SN  \n",
       "6                      contrast     condition_SN  \n",
       "8                   elaboration         joint_NN  \n",
       "9                      sequence   elaboration_NS  \n",
       "10                 cause-effect         joint_NN  \n",
       "...                         ...              ...  \n",
       "2507               cause-effect      sequence_NN  \n",
       "2510                  same-unit     condition_NS  \n",
       "2513                elaboration      contrast_NN  \n",
       "2516                 background   elaboration_NS  \n",
       "2517                      joint  cause-effect_SN  \n",
       "\n",
       "[1095 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "del output2['category_id']\n",
    "output2.to_csv('mispredictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = metrics.classification_report(y_test, ensemble_pred, digits=4, output_dict=True)\n",
    "test_f1 = np.array(\n",
    "    [test_metrics[label].get('f1-score') for label in test_metrics if type(test_metrics[label]) == dict]) * 100\n",
    "\n",
    "test_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble: BiMPM + ESIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls models/label_predictor_bimpm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "vote_predictions() got multiple values for argument 'soft'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-89a2a3695e84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcatboost_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_scikit_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs_catboost_plus_logreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvote_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbimpm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mesim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvote_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatboost_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mensemble_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs_to_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: vote_predictions() got multiple values for argument 'soft'"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "TARGET = 'relation'\n",
    "\n",
    "y_dev, X_dev = dev_samples['relation'].to_frame(), dev_samples.drop('relation', axis=1).drop(\n",
    "    columns=drop_columns + ['category_id', 'index'])\n",
    "\n",
    "X_scaled_np = scaler.transform(X_dev)\n",
    "X_dev = pd.DataFrame(X_scaled_np, index=X_dev.index)\n",
    "\n",
    "bimpm = load_neural_predictions(f'models/label_predictor_bimpm/winter-sweep-1/predictions_dev.json')\n",
    "esim = load_neural_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_dev.json')\n",
    "catboost_predictions = load_scikit_predictions(fs_catboost_plus_logreg, X_dev)\n",
    "\n",
    "tmp = vote_predictions(bimpm, esim, soft=False, weights=[1., 1.])\n",
    "tmp = vote_predictions(tmp, catboost_predictions, soft=True, weights=[1., 1.])\n",
    "ensemble_pred = probs_to_classes(tmp)\n",
    "\n",
    "print('weighted f1: ', metrics.f1_score(y_dev.values, ensemble_pred, average='weighted'))\n",
    "print('macro f1: ', metrics.f1_score(y_dev.values, ensemble_pred, average='macro'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_dev.values, ensemble_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_dev, ensemble_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'relation'\n",
    "\n",
    "y_test, X_test = test_samples[TARGET].to_frame(), test_samples.drop(TARGET, axis=1).drop(\n",
    "    columns=drop_columns + ['category_id', 'index'])\n",
    "\n",
    "X_scaled_np = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_scaled_np, index=X_test.index)\n",
    "\n",
    "bimpm = load_neural_predictions(f'models/label_predictor_bimpm/winter-sweep-1/predictions_test.json')\n",
    "esim = load_neural_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_test.json')\n",
    "catboost_predictions = load_scikit_predictions(fs_catboost_plus_logreg, X_test)\n",
    "\n",
    "tmp = vote_predictions([bimpm, catboost_predictions, esim], soft=True, weights=[2., 1, 15.])\n",
    "\n",
    "ensemble_pred = probs_to_classes(tmp)\n",
    "\n",
    "print('weighted f1: ', metrics.f1_score(y_test.values, ensemble_pred, average='weighted'))\n",
    "print('macro f1: ', metrics.f1_score(y_test.values, ensemble_pred, average='macro'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_test.values, ensemble_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, ensemble_pred, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
